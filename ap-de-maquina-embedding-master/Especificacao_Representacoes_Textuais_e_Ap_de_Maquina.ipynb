{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffq44mMvRKH2"
      },
      "source": [
        "Nesta prática iremos apresentar o uso de embeddings. Para isso, você deve primeiro instalar as dependencias usando `pip install -r requirements.txt` (ou `pip3`, dependendo da forma que seu python está instalado)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/daniel-hasan/ap-de-maquina-embedding\n",
        "!cd ap-de-maquina-embedding && mv * /content/"
      ],
      "metadata": {
        "id": "jm5Yo6sfRcG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2064407d-fe28-4179-ae49-0ea73b2fd97a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ap-de-maquina-embedding'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 72 (delta 23), reused 14 (delta 14), pack-reused 35\u001b[K\n",
            "Receiving objects: 100% (72/72), 609.87 KiB | 13.26 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq7UscpWR7Ip",
        "outputId": "080bc948-f241-4f1d-f42e-0dd538c68ba2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alembic==1.5.8 (from -r requirements.txt (line 1))\n",
            "  Downloading alembic-1.5.8-py2.py3-none-any.whl (159 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/159.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/159.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs==20.3.0 (from -r requirements.txt (line 2))\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cliff==3.7.0 (from -r requirements.txt (line 3))\n",
            "  Downloading cliff-3.7.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes==0.8.2 (from -r requirements.txt (line 4))\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cmd2==1.5.0 (from -r requirements.txt (line 5))\n",
            "  Downloading cmd2-1.5.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama==0.4.4 (from -r requirements.txt (line 6))\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorlog==5.0.1 (from -r requirements.txt (line 7))\n",
            "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting cycler==0.10.0 (from -r requirements.txt (line 8))\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting greenlet==1.0.0 (from -r requirements.txt (line 9))\n",
            "  Downloading greenlet-1.0.0.tar.gz (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata==4.0.1 (from -r requirements.txt (line 10))\n",
            "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
            "Collecting joblib==1.0.1 (from -r requirements.txt (line 11))\n",
            "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver==1.3.1 (from -r requirements.txt (line 12))\n",
            "  Downloading kiwisolver-1.3.1.tar.gz (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Mako==1.1.4 (from -r requirements.txt (line 13))\n",
            "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe==1.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading MarkupSafe-1.1.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib==3.3.4 (from -r requirements.txt (line 15))\n",
            "  Downloading matplotlib-3.3.4.tar.gz (37.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.19.5 (from -r requirements.txt (line 16))\n",
            "  Downloading numpy-1.19.5.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting optuna (from -r requirements.txt (line 17))\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==20.9 (from -r requirements.txt (line 18))\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.1.5 (from -r requirements.txt (line 19))\n",
            "  Downloading pandas-1.1.5.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pbr==5.6.0 (from -r requirements.txt (line 20))\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.3/111.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==8.2.0 (from -r requirements.txt (line 21))\n",
            "  Downloading Pillow-8.2.0.tar.gz (47.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prettytable==2.1.0 (from -r requirements.txt (line 22))\n",
            "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
            "Collecting pyparsing==2.4.7 (from -r requirements.txt (line 23))\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyperclip==1.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (1.8.2)\n",
            "Collecting python-dateutil==2.8.1 (from -r requirements.txt (line 25))\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.2/227.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor==1.0.4 (from -r requirements.txt (line 26))\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting pytz==2021.1 (from -r requirements.txt (line 27))\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML==5.4.1 (from -r requirements.txt (line 28))\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AnOCbMYRKH5"
      },
      "source": [
        "Inicialmente, você deverá baixar os repositórios em português e inglês e salvá-los na pasta `embedding_data` seguindo as seguintes instruções:\n",
        "\n",
        "- [No respositório da USP](http://www.nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc) baixe [este arquivo (Glove 100 dimensões)](http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s100.zip). Ele possui  um pouco mais de 600 mil palavras retiradas de textos de páginas Web tais como a Wikipedia e canais de notícias [(Hartmann et al., 2017)](https://arxiv.org/abs/1708.06025). Descomprima e renomeie o arquivo txt para `glove.pt.100.txt`.\n",
        "\n",
        "- No [repositório de Stanford](https://nlp.stanford.edu/projects/glove/), baixe [este arquivo](http://nlp.stanford.edu/data/glove.6B.zip) use o arquivo . Este arquivo compreende ~400 mil palavras de textos extraidos da Wikipédia e [GigaWord](https://catalog.ldc.upenn.edu/LDC2011T07) [(Pennington et al., 2015)](https://nlp.stanford.edu/pubs/glove.pdf). Descomprima e salve o arquivo com embeddings de 100 dimensões (nome `glove.6B.100d.txt`) na pasta `embedding_data` renomeando esse arquivo para `glove.en.100.txt`.\n",
        "\n",
        "Como você pode perceber, esta prática demandará um espaço livre em disco de aproximadamente 3GB. Os arquivos estão no seguinte formato: em cada linha, uma palavra e N valores representando o valor em cada uma das N dimensões do embedding desta palavra. Por exemplo, caso as palavras `casa`, `redondel` e `rei` sejam representadas por um embedding de 4 dimensões, uma possível representação seria:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s100.zip\n",
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dmv5sYQUXng",
        "outputId": "3078750e-4f3f-44be-a380-83907c10b47e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-06 10:20:55--  http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s100.zip\n",
            "Connecting to 143.107.183.175:22980... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 348388454 (332M) [application/octet-stream]\n",
            "Saving to: ‘download.php?file=embeddings%2Fglove%2Fglove_s100.zip’\n",
            "\n",
            "download.php?file=e 100%[===================>] 332.25M  9.81MB/s    in 35s     \n",
            "\n",
            "2023-12-06 10:21:30 (9.45 MB/s) - ‘download.php?file=embeddings%2Fglove%2Fglove_s100.zip’ saved [348388454/348388454]\n",
            "\n",
            "--2023-12-06 10:21:30--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2023-12-06 10:24:10 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmucvtJKWtAm",
        "outputId": "24910288-b807-4e19-9481-bdc8261b21f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip download.php?file=embeddings%2Fglove%2Fglove_s100.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr_kr_c7W6G_",
        "outputId": "b6ddfdf8-8973-40ad-94fe-43269651c180"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  download.php?file=embeddings%2Fglove%2Fglove_s100.zip\n",
            "  inflating: glove_s100.txt          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv glove_s100.txt /content/embeddings_data/glove.pt.100.txt\n",
        "!mv glove.6B.100d.txt /content/embeddings_data/glove.en.100.txt"
      ],
      "metadata": {
        "id": "KOoMHlhBYXML"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAtYJGYdRKH5"
      },
      "source": [
        "```\n",
        "casa 0.12 0.1 0.5 -0.4\n",
        "redondel 0.2 0.1 -0.4 0.5\n",
        "rei 0.1 0.5 -0.1 0.1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEebJS7fRKH5"
      },
      "source": [
        "A função `get_embedding`, do arquivo `embeddings/utils.py` é responsável por ler esse arquivo e gerar um dicionário em que a chave é a palavra e o valor é sua representação por meio de embeddings. Para a  representação acima, a saída desta função seria seria:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uFp07DYIRKH6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "dict_embedding_ex = {\n",
        "                        \"casa\":np.array([0.12,0.1,0.5,-0.4]),\n",
        "                        \"redondel\":np.array([0.2,0.1,-0.4,0.5]),\n",
        "                        \"rei\":np.array([0.1,0.5,-0.1,0.1]),\n",
        "                    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzS0q5TBRKH6"
      },
      "source": [
        "Nessa função, também é salvo o objeto criado usando [pickle](https://docs.python.org/3/library/pickle.html), assim, a próxima vez que seja lido o embedding, a leitura será mais rápida.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lr77cYfRKH7"
      },
      "source": [
        "**Atividade 1 - obtenção do embedding**: Complete a função `get_embedding` obtendo a palavra e o vetor de embeddings com a dimensão `embeddings_size` substituindo os `None` apropriadamente. O dataset possui algumas incosistencias que você deve considerar ao modificar essas linhas: no dataset em português, a maioria das palavras compostas são separadas por hífen, porém, foi verificado que umas palavras foi separado por espaço. Por caso disso, você deve considerar que as `embeddings_size` últimas posições são os valores de cada dimensão, separados por espaço e, as demais, são a palavra. Sugiro \"brincar\" abaixo com o uso de [índice negativo](https://www.geeksforgeeks.org/python-negative-index-of-element-in-list/) entenda também o [método join](https://www.geeksforgeeks.org/join-function-python/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r4XB2HJmRKH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857f81e6-3423-4827-fbec-d153f2e5d008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'pé de moleque': [ 0.1 -0.5  0.5  0.1 -0.5]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "linha = \"pé de moleque 0.1 -0.5 0.5 0.1 -0.5\"\n",
        "embedding_size = 5\n",
        "arr_line = linha.strip().split()\n",
        "\n",
        "word = \" \".join(arr_line[0:-embedding_size])\n",
        "#colocamos float16 para economizar memória\n",
        "embedding = np.array(arr_line[-embedding_size:], dtype=np.float16)\n",
        "print(f\"'{word}': {embedding}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu6XpH0jRKH8"
      },
      "source": [
        "Execute o teste unitário abaixo para verificar o funcionamento do `get_embeddings`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "168fCbfGRKH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa657db-0add-48fd-cc30-4ab19d0e6e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: rei\n",
            "Palavras ignoradas: 0\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.003s\n",
            "\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "!python3 -m embeddings.embedding_tests TestEmbeddings.test_get_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riYWDO2pRKH8"
      },
      "source": [
        "Execute os embeddings em português e ingles. Não se preocupe com as palavras ignoradas: foram algumas inconsistências no dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2RY8CgT2RKH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3073c8f6-ba69-44de-f0c8-449eb95747f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: the\n",
            "10000: persecution\n",
            "20000: baths\n",
            "30000: mortally\n",
            "40000: 1667\n",
            "50000: bec\n",
            "60000: baek\n",
            "70000: b/w\n",
            "80000: klinghoffer\n",
            "90000: azarov\n",
            "100000: capron\n",
            "110000: perpetua\n",
            "120000: biratnagar\n",
            "130000: 12.74\n",
            "140000: yaffa\n",
            "150000: cryogenics\n",
            "160000: ef1\n",
            "170000: franchetti\n",
            "180000: blintzes\n",
            "190000: birthstones\n",
            "200000: naadam\n",
            "210000: concertation\n",
            "220000: lesticus\n",
            "230000: containerboard\n",
            "240000: boydston\n",
            "250000: afterellen.com\n",
            "260000: acuff-rose\n",
            "270000: close-fitting\n",
            "280000: packbot\n",
            "290000: comptel\n",
            "300000: tanke\n",
            "310000: saraju\n",
            "320000: rouiba\n",
            "330000: discomfit\n",
            "340000: numurkah\n",
            "350000: hla-a\n",
            "360000: 90125\n",
            "370000: zipkin\n",
            "380000: lombarde\n",
            "390000: 1.137\n",
            "Palavras ignoradas: 0\n",
            "10000: distribuída\n",
            "20000: selena\n",
            "30000: sailor\n",
            "40000: aguaceiros\n",
            "50000: retrô\n",
            "60000: indesmentível\n",
            "70000: kouchner\n",
            "80000: hoya\n",
            "90000: j&f\n",
            "100000: castra\n",
            "110000: gynt\n",
            "120000: caddie\n",
            "130000: afluíam\n",
            "140000: nashua\n",
            "150000: amok\n",
            "160000: pormenorizou\n",
            "170000: otway\n",
            "180000: bandeirismo\n",
            "190000: críptico\n",
            "200000: kinyarwanda\n",
            "210000: yari\n",
            "220000: picotado\n",
            "230000: roberth\n",
            "240000: illex\n",
            "250000: og00\n",
            "260000: kalin\n",
            "270000: autoridadeslocais\n",
            "280000: goleava\n",
            "290000: mambos\n",
            "300000: interesado\n",
            "310000: cpdlc\n",
            "320000: samenwerkende\n",
            "330000: dimensсo\n",
            "340000: monteggia\n",
            "350000: sangrur\n",
            "360000: wuncler\n",
            "370000: villaputzu\n",
            "380000: zika.a\n",
            "390000: salvares\n",
            "400000: panik\n",
            "410000: hh000\n",
            "420000: boggies\n",
            "430000: super-licença\n",
            "440000: imeadiato\n",
            "450000: ad-libs\n",
            "460000: niinimaki\n",
            "470000: chhu\n",
            "480000: neuropáticas\n",
            "490000: atufando-se\n",
            "500000: megaigrejas\n",
            "510000: analisávamos\n",
            "520000: gitaigo\n",
            "530000: quichua\n",
            "540000: baiocchi\n",
            "550000: jeder\n",
            "560000: tadros\n",
            "570000: celebrou-a\n",
            "580000: hep-ph/0000000\n",
            "590000: palmview\n",
            "600000: tuyakbay\n",
            "610000: comapny\n",
            "620000: júnior.\n",
            "630000: reptiliomorfos\n",
            "640000: aglonas\n",
            "650000: coloniaes\n",
            "660000: frontalot\n",
            "670000: locomotivos\n",
            "680000: podlažice\n",
            "690000: tamta\n",
            "700000: alvadias\n",
            "710000: decoded\n",
            "720000: holder-bank\n",
            "730000: notificar-lhe\n",
            "740000: sipuncula\n",
            "750000: 0000pelos\n",
            "760000: batukada\n",
            "770000: conirostris\n",
            "780000: ergoespirometria\n",
            "790000: harleyville\n",
            "800000: lanlan\n",
            "810000: navigação\n",
            "820000: prolongara-se\n",
            "830000: sitoli\n",
            "840000: vassiljeva\n",
            "850000: ajuda-lhe\n",
            "860000: can-didaturas\n",
            "870000: dewar's\n",
            "880000: fritagelse\n",
            "890000: keppelmann\n",
            "900000: nauti\n",
            "910000: quarteirenses\n",
            "920000: successfactors\n",
            "Palavras ignoradas: 3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from embeddings.utils import get_embedding, plot_words_embeddings\n",
        "\n",
        "str_dataset = \"glove.en.100.txt\"\n",
        "dict_embedding_en = get_embedding(str_dataset)\n",
        "str_dataset = \"glove.pt.100.txt\"\n",
        "dict_embedding_pt = get_embedding(str_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpsfSOlFRKH9"
      },
      "source": [
        "O `plot_words_embeddings` utiliza [Análise de Componentes Principais](https://pt.wikipedia.org/wiki/An%C3%A1lise_de_componentes_principais) (PCA, do inglês Principal Component Analisys) para reduzir cada embedding em 2 dimensões para, logo após, plotar em um grafico a posição dessas palavras de acordo com o embedding. Veja o gráfico apresentado abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DSrtbWjtRKH9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "9f67f7d8-f356-4a57-915f-6a0aacc4fcf1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1300x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "embeddings_to_use = {\n",
        "                        \"en\":\n",
        "                            {\"embedding\":dict_embedding_en,\n",
        "                            \"words_to_use\":[\"prince\",\"princess\",\n",
        "                                            \"duchess\", \"duke\", \"countess\", \"marquis\",\n",
        "                                            \"marquise\",\"king\",\"queen\",\n",
        "                                            \"girl\",\"boy\",\"man\",\"woman\",\"child\"]},\n",
        "\n",
        "                        \"pt\":{\"embedding\":dict_embedding_pt,\n",
        "                          \"words_to_use\":[\"principe\",\"rei\",\"rainha\",\"conde\",\"duquesa\",\"duque\",\"condessa\",\n",
        "                           \"marquês\",\"marquesa\",\n",
        "                           \"homem\",\"mulher\",\"princesa\",\"menina\",\"menino\",\"criança\",\n",
        "                           \"garoto\",\"garota\"]}\n",
        "                }\n",
        "\n",
        "language = \"pt\"#mude de 'pt' para 'en' para ver em ingles tb!\n",
        "plot_words_embeddings(embeddings_to_use[language][\"embedding\"],\n",
        "                    embeddings_to_use[language][\"words_to_use\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob5Rq54ARKH9"
      },
      "source": [
        "No exemplo acima, em português, veja que podemos pensar em dois conceitos claramente divididos: a realeza e o gênero. Pense: neste plano cartesiano, qual eixo corresponde ao conceito de realeza? E o de gênero? Perceba que \"criança\" deveria ter gênero neutro - de fato, está mais próximo do zero. Porém, pode haver algum ruído associando a palavra criança ao genero feminino. Isso, em português, pode haver uma explicação, pois utilizamos o artigo `a`, usado para palavras que remetem ao genero feminino, para se referir a criança. Assim, em português, os artigos podem aproximar uma palavra de gênero neutro a um determinado gênero.\n",
        "\n",
        "\n",
        "Em inglês, não foi possível verificar tão bem a divisão entre os conceitos de `genero` e `realeza`. Isso pode ocorrer devido a redução de dimensionalidade: os conceitos não necessariamente correspondem a um eixo no plano cartesiano e, mesmo se corresponderem, ao mapear itens com $n$ dimensões para um plano bidimensional, pode haver perda de informação. Mesmo assim, conseguimos ver a separação entre palavras da realeza e que não são da realeza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82FanIT4RKH-"
      },
      "source": [
        "Sinta-se livre para \"brincar\", alterando/adicionando palavras. Por exemplo, adicione animais. Devido à ambiguidades, ao dataset e à própria redução de dimensionalidade, podem existir palavras que estão erroneamente próximas, se considerarmos o conceito das mesmas,  principalmente se adicionarmos palavras de conceitos muito distintos. Um detalhe: no dataset em português, há uso de palavras compostas e elas estão (geralmente) separadas por hífen. No dataset em inglês não há palavras compostas.\n",
        "\n",
        "Tanto nesta tarefa quanto na próxima você poderá perceber que os embeddings podem carregar preconceitos. Há uma forma de modificar os vetores para eliminar um determinado tipo de preconceito. Por exemplo, nesses embeddings existirão palavras erronemente similares a um determinado genero e, para corrigir, é possível deixar todas as palavras sem distinção pelo genero. Caso queira saber como minimizar esse problema, veja o artigo \"[Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/abs/1607.06520)\". O título do artigo se remete a um preconceito descoberto ao usar analogias, que será o próximo tópico desta prática."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwY2CJmbRKH-"
      },
      "source": [
        "## Criação de analogias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96fwwRIhRKH-"
      },
      "source": [
        "Outra caracteristica muito interessante ao usar embedding é a criação de analogias. Por exemplo, na frase `homem está para mulher assim como rei está para...`, fazendo operações com os _embeddings_, muitas vezes é possível chegar na analogia mais provável que, neste caso, seria a palavra `rainha`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KwngU4IRKH-"
      },
      "source": [
        "**Atividade 2 - cálculo da analogia: ** Nesta atividade, iremos implementar o método `calcula_embedding_analogia` da classe `Analogy`. Essa classe tem acesso ao dicionário de embeddings e a estrutura KDTree, que iremos explicá-la posteriormente. Considerando a frase <span style=\"color:blue\">\"**palavra_x** está para **palavra_y** assim como **assim_como** esta para **palavra_z**\"</span>, o método `calcula_embedding_analogia` recebe como parâmetro as palavras `palavra_x`, `esta_para` e `assim_ como` e retorna um embedding que, possivelmente, será muito próximo da `palavra_z`.\n",
        "\n",
        "Veja [na aula](https://docs.google.com/presentation/d/1-CggYUA2s7LW7_LcnGv7vlpUGFg9kEWG0j6lWGUnaLI/edit?usp=sharing) como é feito o cálculo e, logo após, faça o teste unitário:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JcvJsztbRKH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575bba75-7976-48dd-92b6-f635959e328f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ -2.0, -1.0, -1.0, ]\n",
            "[ 12.296875, 53.09375, 30.984375, ]\n",
            "[ -10.96875, -30.90625, -9.6015625, ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2, 3],[-1.2, 3.2, 1.2],[12.2, 31.2, 11.2]], dtype=np.float16)\n",
        "esta_para = np.array([[-3, 0, 1],[11, 56, 32.2],[0, 0.2, 0.4]], dtype=np.float16)\n",
        "assim_como = np.array([[2, 1, 1],[0.1,0.3,0],[1.23, 0.1, 1.2]], dtype=np.float16)\n",
        "\n",
        "for i,x_val in enumerate(x):\n",
        "    arr_embedding = assim_como[i]-x[i]+esta_para[i]\n",
        "    print(\"[\",end=\" \")\n",
        "    for val in arr_embedding:\n",
        "        print(float(val),end=\", \")\n",
        "    print(\"]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SDMCdBLgRKH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb04244-0484-4300-d591-7f248869be66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.002s\n",
            "\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "!python3 -m embeddings.embedding_tests TestEmbeddings.test_calculo_analogia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJz-kHY3RKH_"
      },
      "source": [
        "**Atividade 3 - busca da palavra mais similar:** O cálculo da atividade anterior resultou em um embedding e, agora, precisamos  procuramos a palavra mais próxima a este embedding obtido. Para isso, precisamos de: (1) uma forma eficiente para percorrer os embeddings para descobrir o mais similar; (2) uma métrica de similaridade/distância;\n",
        "\n",
        "**Como percorrer embeddings?** Para encontrarmos os embeddings similares, uma alternativa seria percorrer todos os vetores de embeddings e encontrar o mais similar. Porém, como estamos trabalhando com centenas de milhares de embeddings, essa operação seria muito custosa. Para isso, podemos usar uma estrutura de dados chamada **KDTree**. KDtree é uma arvore que organiza dados espaciais de tal forma que conseguimos alcançar elementos similares de forma mais eficiente. Caso esteja interessado em mais detalhes, [veja este video](https://www.youtube.com/watch?v=Glp7THUpGow).\n",
        "\n",
        "**Qual métrica de distancia/similaridade usaremos?**  Já foi demonstrado que esta métrica é eficiente para similaridade entre embeddings é a distância euclidiana [(Pennington et al., 2015)](https://nlp.stanford.edu/pubs/glove.pdf). A [distancia euclidiana](https://pt.wikipedia.org/wiki/Dist%C3%A2ncia_euclidiana) entre dois pontos $p$ e $q$ é calculada por meio do tamanho da linha entre esses pontos. Para um espaço bidimensional, considerando que os pontos $p$ e $q$ são representados pelas coordenadas $(p_1,p_2)$ e $(q_1,q_2)$, respectivamente, a equação é dada pela seguinte fórmula: $d(p,q) = \\sqrt{(p_1-q_1)^2+(p_2-q_2)^2}$ veja uma representação gráfica:\n",
        "\n",
        "<img width=\"400px\" src=\"https://github.com/daniel-hasan/ap-de-maquina-embedding/blob/master/img/distancia_euclidiana.svg?raw=1\">\n",
        "\n",
        "Esta métrica pode ser generalizada para um espaço n-dimensional e o cálculo seria: $d(p,q) = \\sqrt{(p_1-q_1)^2+(p_2-q_2)^2+...+(p_n-q_n)^n}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxryJPgzRKH_"
      },
      "source": [
        "Assim, nesta atividade iremos utilizar [a implementação do kdtree do scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html). Nessa estrutura, é possível armazenar os embeddings e, logo após fazer consultas eficientes para, por exemplo, procurar os k elementos mais próximos. Veja o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-TjQtN0eRKH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b3d553-ef2f-4e89-8afd-20c69e7ca752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O ponto [3, 3] é o 1º ponto mais próximo de [3, 2] distância: 1.0\n",
            "O ponto [2, 2] é o 2º ponto mais próximo de [3, 2] distância: 1.0\n",
            "O ponto [1, 1] é o 3º ponto mais próximo de [3, 2] distância: 2.23606797749979\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KDTree\n",
        "elementos = [[1,1],\n",
        "             [2,2],\n",
        "             [3,3],\n",
        "             [4,4],\n",
        "             [5,5],\n",
        "             [6,6],\n",
        "             ]\n",
        "#os elementos são passados como parametro na construção do KDTree junto com a métrica\n",
        "#de distancia que iremos usar\n",
        "kdtree = KDTree(elementos,  metric='euclidean')\n",
        "\n",
        "#retorna os 2 elementos mais próximos e sua distancia\n",
        "#como podemos fazer uma consulta por lista de pontos, temos que\n",
        "#passar uma lista de pontos como parametro\n",
        "ponto = [3,2]\n",
        "distancia,pos_mais_prox = kdtree.query([ponto], k=3, return_distance=True)\n",
        "for i,pos in enumerate(pos_mais_prox[0]):\n",
        "    elemento = elementos[pos]\n",
        "    distancia_ponto = distancia[0][i]\n",
        "    print(f\"O ponto {elemento} é o {i+1}º ponto mais próximo de {ponto} distância: {distancia_ponto}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9YdgTcRKH_"
      },
      "source": [
        "Dessa forma, cada embedding pode ser armazenado no KTree para, logo após, obtermos os embeddings mais próximos a um embedding em questão. Não é possível armazenar na estrutura do KDTree a palavra referente a cada embedding representado, por isso, armazenamos essa estrutura como um atributo da classe `KDTreeEmbedding` (arquivo `utils.py`) que armazena também os atributos `pos_to_word` mapeando, para cada posição a palavra correspondente e o atributo `word_to_pos` que faz o oposto: mapeia, para cada palavra, a posição correspondente. Veja no construtor de `KDTreeEmbedding` como é criado o KDTree. Nela, também será salvo um arquivo com a implementação do KDtree e os atributos `pot_to_word` e `word_to_pos` isso é necessário pois a criação da KDTree é muito custosa.\n",
        "\n",
        "\n",
        "Nesta atividade, você deverá implementar `get_most_similar_embedding` que obtém as $k$ palavras mais similares à palavra (ou embedding) representado pelo parâmetro `query` por meio do método `query` da KDTree. O parâmetro `query` pode ser a palavra (`string`) ou o proprio embedding (`np.array`). Logo após, implemente também o método `get_embeddings_by_similarity` que utiliza o método `query_radius` ([veja documentação](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree.query_radius)) que retorna todas as palavras que estão em um raio de `max_distance` da palavra alvo especificada pelo parametro `query`. Para ambas as implementações, utiliza-se o método `positions_to_word`, já implementado, para retornar as palavras de acordo com as posições indicadas. Caso haja alguma palavra a ser ignorada em `words_to_ignore` ela será excluída também no método `positions_to_word`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bziYVvD5RKIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed73f260-edee-407c-91da-6ebc6e2204be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.001s\n",
            "\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "!python3 -m embeddings.embedding_tests TestEmbeddings.test_get_most_similar_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "188TPc9XRKIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c438c6-eeec-4d5b-b930-a5fe261398f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.001s\n",
            "\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "!python3 -m embeddings.embedding_tests TestEmbeddings.test_embeddings_by_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekFml5O0RKIA"
      },
      "source": [
        "Agora, você pode testar os métodos utilizando os datasets de embeddings. Lembre-se  que o KDTree pode demorar mais de 30 minutos para ser criado na primeira execução de cada idioma. Caso queira testar para o inglês, não esqueça de mudar de `\"kdtree.pt.p\"` para `\"kdtree.en.p\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4pdwXT1BRKIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17233fb5-67d0-4a15-c3c0-bd0c048f8d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000: distribuída\n",
            "20000: selena\n",
            "30000: sailor\n",
            "40000: aguaceiros\n",
            "50000: retrô\n",
            "60000: indesmentível\n",
            "70000: kouchner\n",
            "80000: hoya\n",
            "90000: j&f\n",
            "100000: castra\n",
            "110000: gynt\n",
            "120000: caddie\n",
            "130000: afluíam\n",
            "140000: nashua\n",
            "150000: amok\n",
            "160000: pormenorizou\n",
            "170000: otway\n",
            "180000: bandeirismo\n",
            "190000: críptico\n",
            "200000: kinyarwanda\n",
            "210000: yari\n",
            "220000: picotado\n",
            "230000: roberth\n",
            "240000: illex\n",
            "250000: og00\n",
            "260000: kalin\n",
            "270000: autoridadeslocais\n",
            "280000: goleava\n",
            "290000: mambos\n",
            "300000: interesado\n",
            "310000: cpdlc\n",
            "320000: samenwerkende\n",
            "330000: dimensсo\n",
            "340000: monteggia\n",
            "350000: sangrur\n",
            "360000: wuncler\n",
            "370000: villaputzu\n",
            "380000: zika.a\n",
            "390000: salvares\n",
            "400000: panik\n",
            "410000: hh000\n",
            "420000: boggies\n",
            "430000: super-licença\n",
            "440000: imeadiato\n",
            "450000: ad-libs\n",
            "460000: niinimaki\n",
            "470000: chhu\n",
            "480000: neuropáticas\n",
            "490000: atufando-se\n",
            "500000: megaigrejas\n",
            "510000: analisávamos\n",
            "520000: gitaigo\n",
            "530000: quichua\n",
            "540000: baiocchi\n",
            "550000: jeder\n",
            "560000: tadros\n",
            "570000: celebrou-a\n",
            "580000: hep-ph/0000000\n",
            "590000: palmview\n",
            "600000: tuyakbay\n",
            "610000: comapny\n",
            "620000: júnior.\n",
            "630000: reptiliomorfos\n",
            "640000: aglonas\n",
            "650000: coloniaes\n",
            "660000: frontalot\n",
            "670000: locomotivos\n",
            "680000: podlažice\n",
            "690000: tamta\n",
            "700000: alvadias\n",
            "710000: decoded\n",
            "720000: holder-bank\n",
            "730000: notificar-lhe\n",
            "740000: sipuncula\n",
            "750000: 0000pelos\n",
            "760000: batukada\n",
            "770000: conirostris\n",
            "780000: ergoespirometria\n",
            "790000: harleyville\n",
            "800000: lanlan\n",
            "810000: navigação\n",
            "820000: prolongara-se\n",
            "830000: sitoli\n",
            "840000: vassiljeva\n",
            "850000: ajuda-lhe\n",
            "860000: can-didaturas\n",
            "870000: dewar's\n",
            "880000: fritagelse\n",
            "890000: keppelmann\n",
            "900000: nauti\n",
            "910000: quarteirenses\n",
            "920000: successfactors\n",
            "Palavras ignoradas: 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.0,\n",
              "  3.8529124618382,\n",
              "  3.879822890301186,\n",
              "  4.110205347652384,\n",
              "  4.330550049048636],\n",
              " ['carro', 'veículo', 'caminhão', 'motorista', 'moto'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from embeddings.utils import get_embedding, KDTreeEmbedding\n",
        "str_dataset = \"glove.pt.100.txt\"\n",
        "kdtree_file = \"kdtree.pt.p\"\n",
        "dict_embedding = get_embedding(str_dataset)\n",
        "kdtree = KDTreeEmbedding(dict_embedding, kdtree_file)\n",
        "kdtree.get_most_similar_embedding(\"carro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC7h9KpaRKIB"
      },
      "source": [
        "**Atividade 5 - 💞 apresentando as analogias 💞:** Agora você deverá implementar o método `analogia` da classe `Analogy` que deverá utilizar os métodos `calcula_embedding_analogia` e o `get_most_similar_embedding` para retornar as 4 palavras mais prováveis para completar uma determinada analogia, com os parâmetros indicados. Caso, dentre as 4 palavras, haja uma palavra dos pârametro de entrada, a mesma pode ser excluída, retorando menos palavras. Por exemplo, considerando \"**rei** está para **rainha** assim como **homem** está para...\", caso uma das palavras de saída para essa entrada  seja `rainha`, o método poderá retornar 3 palavras (eliminando a palavra rainha). Isso já é considerado no método `get_most_similar_embedding`. Lembre-se que o método `get_most_similar_embedding` é da classe KDTreeEmbedding e a `Analogy` possui o atributo `kdtree_embedding` que é uma instância da classe `KDTreeEmbedding`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BYLUr3kORKIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3b4189-4565-447f-eb82-4d1f60560d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.001s\n",
            "\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "!python3 -m embeddings.embedding_tests TestEmbeddings.test_analogy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPFRpfgLRKIB"
      },
      "source": [
        "Veja as analogias (brinque à vontade com a representação em português e em inglês)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0Z6HybrSRKIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6187ee6a-fcc1-41ec-d601-fb52804a9d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000: distribuída\n",
            "20000: selena\n",
            "30000: sailor\n",
            "40000: aguaceiros\n",
            "50000: retrô\n",
            "60000: indesmentível\n",
            "70000: kouchner\n",
            "80000: hoya\n",
            "90000: j&f\n",
            "100000: castra\n",
            "110000: gynt\n",
            "120000: caddie\n",
            "130000: afluíam\n",
            "140000: nashua\n",
            "150000: amok\n",
            "160000: pormenorizou\n",
            "170000: otway\n",
            "180000: bandeirismo\n",
            "190000: críptico\n",
            "200000: kinyarwanda\n",
            "210000: yari\n",
            "220000: picotado\n",
            "230000: roberth\n",
            "240000: illex\n",
            "250000: og00\n",
            "260000: kalin\n",
            "270000: autoridadeslocais\n",
            "280000: goleava\n",
            "290000: mambos\n",
            "300000: interesado\n",
            "310000: cpdlc\n",
            "320000: samenwerkende\n",
            "330000: dimensсo\n",
            "340000: monteggia\n",
            "350000: sangrur\n",
            "360000: wuncler\n",
            "370000: villaputzu\n",
            "380000: zika.a\n",
            "390000: salvares\n",
            "400000: panik\n",
            "410000: hh000\n",
            "420000: boggies\n",
            "430000: super-licença\n",
            "440000: imeadiato\n",
            "450000: ad-libs\n",
            "460000: niinimaki\n",
            "470000: chhu\n",
            "480000: neuropáticas\n",
            "490000: atufando-se\n",
            "500000: megaigrejas\n",
            "510000: analisávamos\n",
            "520000: gitaigo\n",
            "530000: quichua\n",
            "540000: baiocchi\n",
            "550000: jeder\n",
            "560000: tadros\n",
            "570000: celebrou-a\n",
            "580000: hep-ph/0000000\n",
            "590000: palmview\n",
            "600000: tuyakbay\n",
            "610000: comapny\n",
            "620000: júnior.\n",
            "630000: reptiliomorfos\n",
            "640000: aglonas\n",
            "650000: coloniaes\n",
            "660000: frontalot\n",
            "670000: locomotivos\n",
            "680000: podlažice\n",
            "690000: tamta\n",
            "700000: alvadias\n",
            "710000: decoded\n",
            "720000: holder-bank\n",
            "730000: notificar-lhe\n",
            "740000: sipuncula\n",
            "750000: 0000pelos\n",
            "760000: batukada\n",
            "770000: conirostris\n",
            "780000: ergoespirometria\n",
            "790000: harleyville\n",
            "800000: lanlan\n",
            "810000: navigação\n",
            "820000: prolongara-se\n",
            "830000: sitoli\n",
            "840000: vassiljeva\n",
            "850000: ajuda-lhe\n",
            "860000: can-didaturas\n",
            "870000: dewar's\n",
            "880000: fritagelse\n",
            "890000: keppelmann\n",
            "900000: nauti\n",
            "910000: quarteirenses\n",
            "920000: successfactors\n",
            "Palavras ignoradas: 3\n",
            "brasil está para brasilia assim como...\n",
            "\tperu está para aneura (ou ['trong', 'lacrima', 'vorskla'])\n",
            "\tgana está para aneura (ou ['seraing', 'fene', 'dewsbury', 'gria'])\n",
            "\tjapão está para yeonpyeong (ou ['lieja', 'pottstown', 'belém-pa', 'flexi'])\n",
            "\tespanha está para logroño (ou ['valladolid', 'kalapa', 'cádiz', 'baiona'])\n",
            "\tindia está para vjm00 (ou ['mailman', 'excursion', 'nsi', 'clementia'])\n",
            "bahia está para salvador assim como...\n",
            "\tacre está para macapá (ou ['aracaju', 'cuiabá'])\n",
            "\talagoas está para aracaju (ou ['maceió', 'teresina'])\n",
            "\tamapá está para macapá (ou ['amazonas', 'xinguara'])\n",
            "\tamazonas está para maceió (ou ['aracaju', 'macapá'])\n",
            "\tceará está para maceió (ou ['cuiabá', 'aracaju', 'recife'])\n",
            "\tgoiás está para goiânia (ou ['cuiabá', 'aracaju', 'macapá'])\n",
            "brasil está para feijoada assim como...\n",
            "\titalia está para esparguete (ou ['via-crúcis', 'negundo', 'pana', 'taxifolia'])\n",
            "\testados-unidos está para cebolada (ou ['portugas', 'atribuindo-os', 'bróculos', 'surtida'])\n",
            "\tinglaterra está para worcestershire (ou ['falmouth', 'lincolnshire', 'lowestoft'])\n",
            "\targentina está para retrete (ou ['esparguete', 'carnico', 'frita'])\n",
            "\tperu está para frita (ou ['molho', 'guisado', 'assado'])\n",
            "homem está para mulher assim como...\n",
            "\tgaroto está para menina (ou ['garota', 'namorada', 'mãe', 'irmã'])\n",
            "\trei está para rainha (ou ['princesa', 'esposa', 'príncipe'])\n",
            "\tpríncipe está para princesa (ou ['rainha', 'filha', 'esposa'])\n",
            "\tpai está para filha (ou ['mãe', 'esposa', 'irmã', 'marido'])\n",
            "\tcavalo está para dama (ou ['égua', 'carruagem', 'irmã'])\n",
            "\tgarçon está para cabeleireira (ou ['edna', 'pescadora', 'elisabetha'])\n",
            "grande está para pequeno assim como...\n",
            "\tcheio está para armário (ou ['saco', 'gato', 'minúsculo'])\n",
            "\talto está para baixo (ou ['comprido', 'redondo'])\n",
            "\tforte está para fraco (ou ['parecido', 'baixo'])\n",
            "\tlargo está para beco (ou ['fronteiro', 'comprido'])\n",
            "pelé está para futebol assim como...\n",
            "\ttyson está para hóquei (ou ['basquetebol', 'campeão'])\n",
            "\tbolt está para hóquei (ou ['atletismo', 'ciclismo'])\n",
            "\tsenna está para ciclismo (ou ['liga', 'campeonato'])\n",
            "atena está para sabedoria assim como...\n",
            "\tafrodite está para bondade (ou ['harmonia', 'compaixão', 'benevolência'])\n",
            "\tposeidon está para inefável (ou ['sábio', 'bondade', 'intuição'])\n",
            "\tzeus está para compaixão (ou ['bondade', 'alma', 'espiritual'])\n",
            "\tatena está para bondade (ou ['serenidade', 'generosidade', 'compaixão'])\n",
            "cruzeiro está para raposa assim como...\n",
            "\tatlético está para galo (ou ['csa', 'azulão'])\n",
            "\tgremio está para exquisite (ou ['arara-azul-de-lear', 'noreña', 'bifobia'])\n",
            "\tpalmeiras está para macaca (ou ['verdão', 'galo'])\n",
            "\tcorinthians está para timão (ou ['galo', 'verdão'])\n"
          ]
        }
      ],
      "source": [
        "from embeddings.utils import *\n",
        "dict_embedding = get_embedding( \"glove.pt.100.txt\",100)\n",
        "obj_analogy = Analogy(dict_embedding,\"kdtree.pt.p\")\n",
        "\n",
        "\n",
        "dict_analogias = {(\"brasil\",\"brasilia\"):[\"peru\",\"gana\",\"japão\",\"espanha\",\"india\"],\n",
        "                  (\"bahia\",\"salvador\"):[\"acre\",\"alagoas\",\"amapá\",\"amazonas\",\"ceará\",\"goiás\"],\n",
        "                  (\"brasil\",\"feijoada\"):[\"italia\",\"estados-unidos\",\"inglaterra\",\"argentina\",\"peru\"],\n",
        "                  (\"homem\",\"mulher\"):[\"garoto\",\"rei\",\"príncipe\",\"pai\",\"cavalo\",\"garçon\"],\n",
        "                  (\"grande\",\"pequeno\"):[\"cheio\",\"alto\",\"forte\",\"largo\"],\n",
        "                  (\"pelé\",\"futebol\"):[\"tyson\",\"bolt\",\"senna\"],\n",
        "                  (\"atena\",\"sabedoria\"):[\"afrodite\",\"poseidon\",\"zeus\",\"atena\"],\n",
        "                  (\"cruzeiro\",\"raposa\"):[\"atlético\",\"gremio\",\"palmeiras\",\"corinthians\"],\n",
        "                 }\n",
        "\n",
        "for (palavra,esta_para), arr_assim_como in dict_analogias.items():\n",
        "    print(f\"{palavra} está para {esta_para} assim como...\")\n",
        "    for assim_como in arr_assim_como:\n",
        "        palavras = obj_analogy.analogia(palavra,esta_para,assim_como)\n",
        "        print(f\"\\t{assim_como} está para {palavras[0]} (ou {palavras[1:]})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkIH_pLhRKIC"
      },
      "source": [
        "Algumas limitações desses embeddings é a dependência de idiomas e que palavras ambiguas não são tratadas. Por exemplo, Jaguar pode ser uma marca de carro ou um animal, dependendo do contexto.  Para diminuir o problema de ambuiguidades, o [BERT](https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/) é um embedding que a representação da palavra é diferente de acordo com o seu contexto. O [MUSE](https://github.com/facebookresearch/MUSE) é um embedding multilingue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M_B9xLIRKIC"
      },
      "source": [
        "## Representação textual usando embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA9KCphzRKIC"
      },
      "source": [
        "Muitas vezes, precisamos de um único vetor para representar uma frase ou um texto ainda maior. Para isso, podemos usar a representação Bag of Words ou, ainda, representar por palavras chaves ou utilizarmos uma combinação de nossas representações por palavras. Neste tutorial, iremos mostrar como combinar embeddings de palavras e usar a representação por palavras chaves - podendo, inclusive, fazer uma expansão de palavras chaves por embeddings.\n",
        "\n",
        "Para isso, iremos usar o seguinte contexto: por meio de um dataset de revisões de produto da amazon, deseja-se prever automaticamente o sentimento do mesmo (positivo ou negativo). Utilizou-se uma amostra do [dataset do Kaggle para este exemplo](https://www.kaggle.com/bittlingmayer/amazonreviews). Veja abaixo o dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LS-HT_VrRKIC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "64d493bf-b683-4168-c1e7-2656d36be898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     class\n",
              "id                                                                 \n",
              "204215  Do NOT WASTE Your Time: This book, to put it n...  negative\n",
              "208138  Peels the paint off the walls: I first heard t...  positive\n",
              "157010  History With Modern Appeal: This is a must rea...  positive\n",
              "274316  Worse Music cd ever: I tried putting this in a...  negative\n",
              "57708   Deliberately Obtuse Nonsense: I don't know wha...  negative\n",
              "...                                                   ...       ...\n",
              "29215   Better than the movie?: YES! This book gets be...  positive\n",
              "256457  The Best RE yet: This is the best in the RE se...  positive\n",
              "210215  What are they waiting for?: This has got to be...  positive\n",
              "200693  Hollywood - promoting the Antichrist again?: C...  negative\n",
              "169551  Best American TV Series Ever: With its combina...  positive\n",
              "\n",
              "[3000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-225dd76a-b58d-45e0-93fe-26e807dbae29\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204215</th>\n",
              "      <td>Do NOT WASTE Your Time: This book, to put it n...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208138</th>\n",
              "      <td>Peels the paint off the walls: I first heard t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157010</th>\n",
              "      <td>History With Modern Appeal: This is a must rea...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274316</th>\n",
              "      <td>Worse Music cd ever: I tried putting this in a...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57708</th>\n",
              "      <td>Deliberately Obtuse Nonsense: I don't know wha...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29215</th>\n",
              "      <td>Better than the movie?: YES! This book gets be...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256457</th>\n",
              "      <td>The Best RE yet: This is the best in the RE se...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210215</th>\n",
              "      <td>What are they waiting for?: This has got to be...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200693</th>\n",
              "      <td>Hollywood - promoting the Antichrist again?: C...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169551</th>\n",
              "      <td>Best American TV Series Ever: With its combina...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-225dd76a-b58d-45e0-93fe-26e807dbae29')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-225dd76a-b58d-45e0-93fe-26e807dbae29 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-225dd76a-b58d-45e0-93fe-26e807dbae29');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-934ee4a5-f541-4a09-94df-d70a79ec7b46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-934ee4a5-f541-4a09-94df-d70a79ec7b46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-934ee4a5-f541-4a09-94df-d70a79ec7b46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_amazon_reviews = pd.read_csv(\"datasets/amazon_reviews_mini.txt\",index_col=\"id\")\n",
        "df_amazon_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5raAVK1RKIC"
      },
      "source": [
        "Em um método de aprendizado de maquina, cada instância deve ser representada por um vetor numérico utilizando as representações ditas anteriormente. Iremos ilustrar cada exemplo utilizando uma pequena subamostra desta amostra com 5 exemplos positivos e 5 negativos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qa6s5xlIRKID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "d369a741-a28e-4662-902f-31cc0c223d89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     class\n",
              "id                                                                 \n",
              "208138  Peels the paint off the walls: I first heard t...  positive\n",
              "157010  History With Modern Appeal: This is a must rea...  positive\n",
              "101657  NIV Bible: The NIV Bible is good, but I wish I...  positive\n",
              "49225   pouch can be better: I recently bought it at A...  positive\n",
              "158265  Great book!: Dawn of a Thousand Nights is extr...  positive\n",
              "204215  Do NOT WASTE Your Time: This book, to put it n...  negative\n",
              "274316  Worse Music cd ever: I tried putting this in a...  negative\n",
              "57708   Deliberately Obtuse Nonsense: I don't know wha...  negative\n",
              "200048  Disappointed: Very small wipes canister, not v...  negative\n",
              "60933   The most horrible Blu-Ray: First, Night scenes...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29a099f3-1fb3-436f-836a-718b31844e9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>208138</th>\n",
              "      <td>Peels the paint off the walls: I first heard t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157010</th>\n",
              "      <td>History With Modern Appeal: This is a must rea...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101657</th>\n",
              "      <td>NIV Bible: The NIV Bible is good, but I wish I...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49225</th>\n",
              "      <td>pouch can be better: I recently bought it at A...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158265</th>\n",
              "      <td>Great book!: Dawn of a Thousand Nights is extr...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204215</th>\n",
              "      <td>Do NOT WASTE Your Time: This book, to put it n...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274316</th>\n",
              "      <td>Worse Music cd ever: I tried putting this in a...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57708</th>\n",
              "      <td>Deliberately Obtuse Nonsense: I don't know wha...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200048</th>\n",
              "      <td>Disappointed: Very small wipes canister, not v...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60933</th>\n",
              "      <td>The most horrible Blu-Ray: First, Night scenes...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29a099f3-1fb3-436f-836a-718b31844e9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29a099f3-1fb3-436f-836a-718b31844e9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29a099f3-1fb3-436f-836a-718b31844e9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-49c3e440-ecda-45c9-862f-710bc636353e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49c3e440-ecda-45c9-862f-710bc636353e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-49c3e440-ecda-45c9-862f-710bc636353e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df_positive = df_amazon_reviews[df_amazon_reviews[\"class\"]==\"positive\"][:5]\n",
        "df_negative = df_amazon_reviews[df_amazon_reviews[\"class\"]==\"negative\"][:5]\n",
        "df_amazon_mini = pd.concat([df_positive,df_negative])\n",
        "df_amazon_mini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC0j-sR1RKID"
      },
      "source": [
        "**Bag of Words: ** um exemplo simples, sem usar embeddings, é a representação em bag of words, **já discutido aqui**. Assim, podemos  usar a classe `BagOfWords` que está no arquivo `textual_representation.py`. Para as representações bag of words, usaremos a função bag_of_words abaixo. Usando esta representação o nosso dataset ficaria representado da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZInuadjhRKID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "51540412-9bda-4262-d7d8-868abe3e4ee9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              13        16        18        20        21        70  absolute  \\\n",
              "id                                                                             \n",
              "208138  0.115992  0.231984  0.115992  0.115992  0.115992  0.115992  0.115992   \n",
              "157010  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "101657  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "49225   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "158265  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "204215  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "274316  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "57708   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "200048  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "60933   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "          actors     ahead     album  ...    wooden   working     world  \\\n",
              "id                                    ...                                 \n",
              "208138  0.000000  0.115992  0.115992  ...  0.000000  0.000000  0.000000   \n",
              "157010  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.239204   \n",
              "101657  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "49225   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "158265  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "204215  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "274316  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "57708   0.129047  0.000000  0.000000  ...  0.129047  0.000000  0.000000   \n",
              "200048  0.000000  0.000000  0.000000  ...  0.000000  0.223607  0.000000   \n",
              "60933   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "\n",
              "           worse     worst      wow  wrenching   written     years     class  \n",
              "id                                                                            \n",
              "208138  0.000000  0.000000  0.00000   0.115992  0.000000  0.000000  positive  \n",
              "157010  0.000000  0.000000  0.00000   0.000000  0.000000  0.119602  positive  \n",
              "101657  0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  positive  \n",
              "49225   0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  positive  \n",
              "158265  0.000000  0.000000  0.00000   0.000000  0.245462  0.000000  positive  \n",
              "204215  0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  negative  \n",
              "274316  0.283463  0.000000  0.00000   0.000000  0.000000  0.000000  negative  \n",
              "57708   0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  negative  \n",
              "200048  0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  negative  \n",
              "60933   0.000000  0.273879  0.13694   0.000000  0.000000  0.000000  negative  \n",
              "\n",
              "[10 rows x 250 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e6863b3-2c00-4ec3-84bb-e22c2a3c90eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>13</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>70</th>\n",
              "      <th>absolute</th>\n",
              "      <th>actors</th>\n",
              "      <th>ahead</th>\n",
              "      <th>album</th>\n",
              "      <th>...</th>\n",
              "      <th>wooden</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrenching</th>\n",
              "      <th>written</th>\n",
              "      <th>years</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>208138</th>\n",
              "      <td>0.115992</td>\n",
              "      <td>0.231984</td>\n",
              "      <td>0.115992</td>\n",
              "      <td>0.115992</td>\n",
              "      <td>0.115992</td>\n",
              "      <td>0.115992</td>\n",
              "      <td>0.115992</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115992</td>\n",
              "      <td>0.115992</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.115992</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157010</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.239204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.119602</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101657</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49225</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158265</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.245462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204215</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274316</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57708</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129047</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.129047</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200048</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.223607</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60933</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.273879</td>\n",
              "      <td>0.13694</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 250 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e6863b3-2c00-4ec3-84bb-e22c2a3c90eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e6863b3-2c00-4ec3-84bb-e22c2a3c90eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e6863b3-2c00-4ec3-84bb-e22c2a3c90eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c8bef0b5-2022-47ad-a495-e41d34e129ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8bef0b5-2022-47ad-a495-e41d34e129ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c8bef0b5-2022-47ad-a495-e41d34e129ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from embeddings.textual_representation import BagOfWords\n",
        "#o vocabulario, quando vazio, será considerado todas as palavra (menos stopwords)\n",
        "def bag_of_words(data, vocabulary=None):\n",
        "    #obtem stopwords\n",
        "    stop_words = set()\n",
        "    with open(\"datasets/stopwords.txt\") as stop_file:\n",
        "        stop_words = set(stop_word[:-1] for stop_word in stop_file)\n",
        "\n",
        "    #instancia o bag of words, filtrando stopwords e considerando o vocabulario (se possivel)\n",
        "    bow = BagOfWords(\"bow\", stop_words=list(stop_words), words_to_consider=vocabulary)\n",
        "\n",
        "    #o bag of words, é gerado separadamente a representação do treino e teste\n",
        "    #iremos usar apenas a representação considerando que \"data\" é o treino\n",
        "    data_preproc = bow.preprocess_train_dataset(data, \"class\")\n",
        "\n",
        "    #exibe apenas colunas não zedadas\n",
        "    m2 = (data_preproc != 0).any()\n",
        "    data_preproc = data_preproc[m2.index[m2].tolist()]\n",
        "\n",
        "    return data_preproc\n",
        "bag_of_words(df_amazon_mini)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oXtrhowRKID"
      },
      "source": [
        "**Bag of words (filtrado por palavras chaves e embeddings similares)** Como bag of words é uma representação com milhares de atributos, poderiamos fazer uma restrição por palavras chaves. Por exemplo, caso usássemos como vocabulário do bag of words baseado nas palavras obtidas da roda de emoções proposta por [Scherer K., (2005)](https://journals.sagepub.com/doi/pdf/10.1177/0539018405058216):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2QOCcrpxRKID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1d17d042-2f38-418c-ba36-97f29fc7603c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'relief, dumbfounded, nausea, contentment, resent, delight, ardor, mad, ecstatic, interest, furious, buoyancy, rage, contempt, dislike, tedious, bliss, ashamed, chagrin, boredom, derision, anger, angry, exaltation, surprise, shame, embarrassing, enthusiasm, hope, thunderstruck, happy, apprehensive, anguish, animation, blame, depreciate, incense, infuriating, exhilarating, ennui, astonishing, joy, pride, hopeless, denigration, disgust, acknowledgement, jittery, confident, curious, contrition, guilt, worry, cheer, alert, hostile, aversion, indifference, temper, optimistic, sadness, satisfaction, nervous, enjoy, elation, abashed, fury, abhor, scorn, sick, tear, wrath, comfortable, anxiety, respect, melancholy, euphoria, dejected, disrelish, amazed, recognition, proud, disdain, remorse, happiness, gloom, sad, humiliating, faith'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "emotion_words = {\n",
        "                    \"pride\":{\"proud\"},\n",
        "                    \"elation\":{\"ecstatic\", \"euphoria\", \"exaltation\", \"exhilarating\"},\n",
        "                    \"happiness\":{\"joy\",\"cheer\", \"bliss\", \"delight\", \"enjoy\", \"happy\"},\n",
        "                    \"satisfaction\":{\"comfortable\",\"contentment\"},\n",
        "                    \"relief\":{},\n",
        "                    \"hope\":{\"buoyancy\", \"confident\", \"faith\", \"optimistic\"},\n",
        "                    \"interest\":{\"alert\", \"animation\", \"ardor\", \"curious\",\"enthusiasm\"},\n",
        "                    \"surprise\":{\"amazed\", \"astonishing\", \"dumbfounded\",\"thunderstruck\"},\n",
        "                    \"anxiety\":{\"anguish\",\"anxiety\",\"apprehensive\",\"jittery\",\"nervous\",\"worry\"},\n",
        "                    \"sadness\":{\"chagrin\", \"dejected\", \"gloom\", \"hopeless\", \"melancholy\", \"sad\", \"tear\"},\n",
        "                    \"boredom\":{\"ennui\",\"indifference\",\"tedious\"},\n",
        "                    \"shame\":{\"abashed\", \"ashamed\", \"embarrassing\", \"humiliating\"},\n",
        "                    \"guilt\":{\"blame\", \"contrition\", \"remorse\"},\n",
        "                    \"disgust\":{\"abhor\", \"aversion\", \"dislike\", \"disrelish\", \"nausea\",\"sick\"},\n",
        "                    \"contempt\":{\"denigration\",\"depreciate\",\"derision\",\"disdain\",\"scorn\"},\n",
        "                    \"hostile\":{},\n",
        "                    \"anger\":{\"anger\",\"angry\",\"furious\",\"fury\",\"incense\",\"infuriating\",\n",
        "                                \"mad\",\"rage\",\"resent\",\"temper\",\"wrath\"},\n",
        "                    \"recognition\":{\"respect\",\"acknowledgement\"}\n",
        "            }\n",
        "\n",
        "vocabulary = []\n",
        "for emotion_group, set_keywords in emotion_words.items():\n",
        "    vocabulary.append(emotion_group)\n",
        "    for word in set_keywords:\n",
        "        vocabulary.append(word)\n",
        "vocabulary = set(vocabulary)\n",
        "\", \".join(vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPqzoNHwRKIE"
      },
      "source": [
        "O grande problema é que esse grupo de palavras é muito restrito. Veja como ficou a representação dos nossos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UrEmrcvwRKIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "253d189c-6ace-452b-f52a-a723e9cc1f08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        interest  sick     class\n",
              "id                              \n",
              "208138       0.0   0.0  positive\n",
              "157010       1.0   0.0  positive\n",
              "101657       0.0   0.0  positive\n",
              "49225        0.0   0.0  positive\n",
              "158265       0.0   0.0  positive\n",
              "204215       0.0   0.0  negative\n",
              "274316       0.0   0.0  negative\n",
              "57708        0.0   1.0  negative\n",
              "200048       0.0   0.0  negative\n",
              "60933        0.0   0.0  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-602e9b8d-b6c5-4813-adc2-33c2dbe73ad3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interest</th>\n",
              "      <th>sick</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>208138</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157010</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101657</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49225</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158265</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204215</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274316</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57708</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200048</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60933</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-602e9b8d-b6c5-4813-adc2-33c2dbe73ad3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-602e9b8d-b6c5-4813-adc2-33c2dbe73ad3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-602e9b8d-b6c5-4813-adc2-33c2dbe73ad3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe285a7c-007e-4766-b46a-8ac27619e1bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe285a7c-007e-4766-b46a-8ac27619e1bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe285a7c-007e-4766-b46a-8ac27619e1bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "bag_of_words(df_amazon_mini,vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmaV1IteRKIE"
      },
      "source": [
        "Lembre-se que eliminamos as palavras que não apareceram em nenhuma instancia. Assim, como pode-se observar, apenas duas palavras foram usadas e alguns documentos não possuiam nenhuma palavra. Para ampliar o vocabulário, poderiamos expandir esta representação usando palavras similares a estas de acordo com o nosso embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sQjV8cNCRKIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5593e21-43df-4079-84a6-add4a2fb3da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: the\n",
            "10000: persecution\n",
            "20000: baths\n",
            "30000: mortally\n",
            "40000: 1667\n",
            "50000: bec\n",
            "60000: baek\n",
            "70000: b/w\n",
            "80000: klinghoffer\n",
            "90000: azarov\n",
            "100000: capron\n",
            "110000: perpetua\n",
            "120000: biratnagar\n",
            "130000: 12.74\n",
            "140000: yaffa\n",
            "150000: cryogenics\n",
            "160000: ef1\n",
            "170000: franchetti\n",
            "180000: blintzes\n",
            "190000: birthstones\n",
            "200000: naadam\n",
            "210000: concertation\n",
            "220000: lesticus\n",
            "230000: containerboard\n",
            "240000: boydston\n",
            "250000: afterellen.com\n",
            "260000: acuff-rose\n",
            "270000: close-fitting\n",
            "280000: packbot\n",
            "290000: comptel\n",
            "300000: tanke\n",
            "310000: saraju\n",
            "320000: rouiba\n",
            "330000: discomfit\n",
            "340000: numurkah\n",
            "350000: hla-a\n",
            "360000: 90125\n",
            "370000: zipkin\n",
            "380000: lombarde\n",
            "390000: 1.137\n",
            "Palavras ignoradas: 0\n"
          ]
        }
      ],
      "source": [
        "from embeddings.utils import get_embedding, KDTreeEmbedding\n",
        "dict_embedding = get_embedding(\"glove.en.100.txt\")\n",
        "kdtree_embedding = KDTreeEmbedding(dict_embedding, \"kdt_en.p\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lXoSNApoRKIE"
      },
      "outputs": [],
      "source": [
        "vocabulary_expanded = []\n",
        "for word in vocabulary:\n",
        "    #obtem as 40 mais similares palavras de cada uma do vocab original\n",
        "    _,words = kdtree_embedding.get_most_similar_embedding(word,40)\n",
        "    vocabulary_expanded.extend(words)\n",
        "vocabulary_expanded = set(vocabulary_expanded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZs4yoQURKIG"
      },
      "source": [
        "Veja aqui as palavras usadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xQwYo0A8RKIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7210bc26-4b4c-4aae-e3a9-de68d47cb837"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"coarseness, depressed, rest, cheering, soulful, insist, untruth, maybe, truth, giving, earnestness, prosecution, mad, amused, expectation, predicting, film, rage, misfortune, notice, unbelievable, graciousness, sensitivity, cinematic, risible, entrancing, str94, storyboard, hopes, ashamed, stupefied, disliking, resultant, destitution, tankage, rousing, irritating, garlands, rabbit, eventful, joyless, warning, sympathize, alerts, distaste, befuddling, curiously, filmmakers, scare, stress, academicism, cumbersome, benignly, greg.wilcoxdailynews.com, happy, unforgettable, earthiness, incense, unironic, elderly, self-pity, insulted, adulation, regardless, plausibility, jingoism, signifying, diminishes, reverence, better, kroyts, ambivalence, higher, gloomy, pains, indestructibility, wretched, unfazed, euoplocephalus, incredible, thrown, see, unimpressed, clamor, honored, reminded, plodding, moment, playful, infuriates, relaxed, ironically, fergalicious, boring, anxiety, disheartening, joyful, searing, despondency, hostility, aware, aggressive, js94bb, feel, diarrhoea, crankiness, leery, opposing, popi, cheerleaders, hauteur, faith, undeniable, dispiriting, sake, sorry, frankness, religion, engendered, claiming, mellow, perfect, dizzying, solipsism, flame, fiery, clueless, terrible, goal_montreal, unleash, serenity, timeless, legacy, bloodlust, condescension, perturbed, dreamy, genuine, sent, disney, exoneration, future, particular, given, dismay, disastrous, spirited, blame, arduous, predominance, superlatives, vomiting, fervor, stay, idolize, prompting, insult, assurance, licentiousness, bullets, wishing, engagement, effort, creativity, expressing, exasperated, bittersweet, blames, brominated, amazing, contrarians, uneasiness, creations, overjoyed, frustrated, physicality, pronouncement, k977-1, copal, evildoers, support, vitriol, steadiness, worrying, thank, hydrodynamic, eschew, grossness, sluggishness, impressive, speechless, nervous, acknowledgment, irritability, hubbub, reassured, warn, gentleness, bulletinyyy, insanity, foreboding, de-emphasize, scorn, monotonous, surely, prospects, rehabilitation, kudos, delighted, impatience, appreciative, reconsideration, messiness, resentful, excruciatingly, tiring, payback, coloradans, poignant, .0207, indulged, reverie, vwahr, demonstrators, candle, dampened, anguished, confused, bombast, realize, torches, discombobulated, encouragement, response, bemusement, emasculation, intemperance, mistake, intellectualism, scripts, weird, wrong, precautions, perfectionism, ecstatic, intense, heft, constricting, 24aou94, potpourri, newfound, raised, alarm, newborn, pessimistic, artfulness, acasta, enjoyment, misunderstood, surprising, cramping, unremorseful, admonition, www.slarmy.org, unsure, uncouth, keeping, munificence, flood, scared, howls, complaining, shame, engaged, sloppiness, exactitude, thoughtlessness, understandably, grumble, craving, spite, leniency, pleasurably, put, discouragement, frustrations, though, gentility, gone, remorseful, withering, torment, insensitivity, tempered, optimism, rebelliousness, kd94, heartless, debasement, survivability, peevish, distinction, worry, antsy, uncomfortable, humble, phenomenal, oly-2004-fhockey, bb96, getting, aversion, incomparable, treat, establishment, confusion, inconsequential, laborious, morose, itching, stupendous, thus, captivating, headaches, doom, stirred, abhor, canister, amidst, crazed, strange, glib, anxious, dying, wrath, anticipated, individuality, presume, biotechtrst, devaluing, cramps, complained, believing, healthy, bewildered, mindful, shameful, mystifying, exhilarated, drowsiness, unsatisfied, tellingly, livid, sprayed, spirituality, ignored, discouraged, affected, guffaws, deepens, bloating, apologize, mistaken, nonetheless, http://www.mediabynumbers.com, ballast, giddiness, tranquillity, reflexively, bangkokians, goofiness, accepted, loveliness, moralize, manner, focus, malice, 30-270, buoyant, pathos, cautioned, boredom, firing, worship, anger, em96, menorah, resents, instream, say, convinced, outraged, culpability, bullish, interactive, desultory, summons, distressing, informality, vengeance, explicitness, bullet, propriety, fretted, oly-2004-tennis, integrity, remember, welcome, fun, fool, threatening, unexcited, weary, revelations, rubber, cautious, hell, think, stressed, tumult, troubling, applauding, giddy, sentimentality, curious, lobbing, masterful, guilt, sense, alert, pregnant, demonization, concur, qualms, circularity, 'm, reassure, migraine, nowhere, uninteresting, wacky, heartbreaking, sending, lechery, hypnotised, exclusivism, nonplused, adore, penchant, perplexed, kindling, enthused, freedom, providing, helplessness, drohs, fahnt, fluidity, ferocity, unsatisfying, benumbed, followed, cruel, stranger, unnerving, suspicion, wanderlust, prompted, homoeroticism, fantastic, indeed, terrifying, overabundance, reticence, surprises, oblivious, assist, covetousness, 're, putting, idleness, exultant, devalue, independency, insisted, embrace, wo, enamored, electrifying, fortunate, tears, assure, fired, awe, provide, incensed, anyway, acknowledge, convoluted, irrepressible, combativeness, maddening, cow, staying, documentary, abrade, exoticism, accomplished, hesitation, counter, meant, humiliation, ridiculousness, headache, omnipresence, pleasure, shellshocked, surprise, chore, ordeal, productions, unfriendly, realization, why, debase, terrified, undecipherable, raising, edginess, merits, helpless, defensiveness, .0342, immortality, curiosity, directness, nasty, disconsolate, stressing, mayhem, emphasized, patient, ennui, decisiveness, always, stop-motion, gripped, price, love, glory, monotony, announcement, cue, alarms, committment, patronize, astounded, elegiac, deplore, gobsmacked, pleasantly, plenty, sorrow, starving, callousness, horrendous, fears, disconcerted, homesickness, loneliness, watching, clearly, solemnity, sure, excellence, lust, neuroses, spurred, illumined, recognised, burn, irate, amazement, christ, evoked, concerned, infused, letting, frenzied, regret, pensive, yearning, cared, greeted, dispirited, angering, callous, pathetic, complacency, depth-charged, enthralling, indication, selfishness, evocative, encumber, relentless, irritated, usual, pitiful, thrill, intimacy, unsettling, vigilance, penury, enraging, sublime, resentment, hopefulness, recognizing, .0170, yearn, wariness, crestfallen, unsurprisingly, dumbfounded, savage, humbling, disappointment, sitting, apologies, despises, stubbornness, confess, excercise, dispersed, shouting, frivolity, contempt, patriotism, exploding, apparent, outsiders, downcast, idiocy, theatrical, sanctimony, wonderful, intimation, regards, sleeplessness, appreciation, puzzlement, equate, emotion, worried, demented, definitely, pig, heightened, speculation, understanding, bb94, panic, hysterical, loving, wish, panicky, distraught, demeaning, solitude, perfection, pity, eager, liveliness, inadequacy, disgusting, infuriating, belated, cannons, ornaments, comforted, sympathetic, aches, destitute, tempted, pride, cautiousness, jubilation, foolish, throwing, exuberance, here, acknowledgement, embarassing, presumption, trouble, skittish, embarrassed, myrrh, dissatisfaction, suited, likely, competence, deprogrammed, redemption, hurled, admit, certain, burned, upsetting, politeness, boisterous, useless, elation, dislikes, determination, unserious, http://www.oklahomacitynationalmemorial.org, praise, perplexity, looking, ferocious, studios, exclamations, affirmation, tedium, over-produced, really, easy, purifier, protesting, vilification, revenge, raisonnable, cushioned, censers, opportunity, pixar, ugly, pleading, ornery, tantrums, repudiate, contribution, crowd, wearisome, agony, shortness, principle, motivation, seeing, suzuya, jubilant, ambuscade, insufferable, horrific, else, belligerent, cheerily, riot, puppetry, fulfillment, needs, referring, apathy, erratic, ardor, awesome, passivity, rather, divine, egomania, flabbergasted, good, sensuous, appalling, shocked, odd, cgi, depress, chafe, astounding, esteem, merriment, symbolizes, stupefaction, horrible, tedious, cushioning, threat, implication, unambiguous, admiration, fit, thing, imprimatur, lollipops, unbothered, acquiescence, effervescence, uniqueness, poignancy, innocence, empathy, storytelling, hug, agitated, unhappy, incredulous, greet, films, supportive, unprompted, flamboyance, admiring, greenness, pointless, beast, resenting, spellbinding, musculature, celebrating, resisting, furthermore, fervour, fevers, transcendence, indignant, farcical, cheerfulness, inscrutable, honor, lately, languor, meekness, carnality, grateful, much, nerves, uproar, repetitious, ready, trepidation, guileless, disappointed, perfunctory, sudden, vega@globe.com, quietness, onslaught, 'd, interestingly, looked, protestors, preoccupied, way, montanans, self-monitoring, soothed, rescue, puzzled, stylish, comfortable, luck, shouts, melancholy, investor, bedraggled, wistful, continue, ungenerous, pictures, precocity, suggests, wake, outbursts, yet, imperieuse, attacking, compliments, canisters, romanticize, canonicus, unleashes, .0206, compensator, re-organise, frazzled, believer, angst, unamused, minions, fxff, warlike, recognized, paradoxically, breathtaking, humiliating, sentimental, malevolence, .000105, overwrought, disorientation, crowds, takeover, irked, contentment, cannon, disrespected, celebrate, denial, furious, expect, horrified, importance, insularity, predicament, tragic, skillz, bewilderment, rheology, tired, skeptical, fierce, outspokenness, studio, otherwise, elicited, perceive, depreciated, eagerness, provided, nevertheless, recognize, infuriated, brooding, awful, sprinkled, vatten, lg03, constrain, homeless, demonstrate, retribution, importantly, obsessed, confronted, raucous, enraged, soothe, christian, rejecting, silliness, darkening, overact, aggressiveness, frustration, sparks, shaken, baffling, inexplicable, cartoon, permanence, nice, perspire, cheer, quite, geotagging, celebration, impress, js04bb, affectation, visibly, mo95, nuttiness, circumspect, thankless, editing, satisfaction, abashed, fearlessness, pessimism, lest, insouciance, spared, animated, brutalization, detests, unfortunate, indigestion, invoking, addition, unsettled, protection, essence, antics, lonely, pellets, moral, passion, video, devotion, respect, inattention, wondered, open-mindedness, doomed, annoyed, dehydration, symbolized, opposed, viewed, bb97, embarrassment, feeling, discomfited, mournful, creative, cat, bullishness, remorse, want, distrusted, magnificent, antigravity, sympathy, sensational, promise, sad, firestorm, fend, self-identity, looks, brightly, immediately, heartfelt, impotent, timelessness, desperation, lethargy, needed, tihg, merciless, allied, recovery, frightened, goodness, heartburn, surprised, mesmerizing, glum, explosiveness, unfathomable, impishly, censer, coming, startled, compelled, came, awed, cowardice, self-love, cry, unrelenting, prefer, bemused, cowardliness, ridicule, scapegoating, fear, disgruntled, knowing, saves_mrivera, publicized, ripoffs, unhappiness, abandon, sadly, arguing, concision, strangeness, allusion, sociability, insolence, scorned, comfortably, cathartic, liken, unworldly, photography, unassertive, prideful, doldrums, biodegrade, palpitations, engage, delirious, boldness, jaded, caring, expression, rudeness, surprisingly, discomfort, beguiling, deployed, continuing, undeterred, neither, depreciating, outcry, enjoy, appreciate, pleased, enjoyable, wonder, deliriously, apology, awkwardness, truly, take, triumphalism, ponderous, noting, tearing, childlike, immaturity, loathe, dog, organgn, recognition, success, quick, fearful, acetylene, fatalism, ruminative, srivalo, patterson, dread, god, fading, 'll, affronted, animations, ineptitude, flatten, clumsiness, inconsolable, mesmerized, internalize, irksome, illness, 65stk, hand-drawn, liking, overlong, dispersing, unpleasant, hatred, joyous, heartwarming, madness, forget, clarity, rejoicing, raise, demoralising, benefit, inevitable, satisfied, depressing, bliss, spray, distracting, know, whimsy, individualization, retardants, chagrined, omniscience, dramatic, buying, feistiness, .0163, exaltation, indifferent, abasement, petulance, assistance, nervousness, degrading, anxieties, depredations, heartache, antipathy, rise, ignominious, peeved, skepticism, detestation, termed, privilege, hopelessness, gyroscopic, southpaws, amusing, astonishing, joy, aghast, exasperating, passions, care, danger, lucky, sassacus, jittery, wanted, impressed, peacefulness, apologizing, didacticism, intemperate, antagonistic, catharsis, impatient, explode, startling, rp-1, crunch, hostile, monster, distrust, topside, _____________________________________________, vruhl, behest, tantrum, puzzling, contrary, reaffirmation, spraying, forlorn, lyricism, thrilled, impression, clumsy, script, arrogance, displeasure, perceived, evacuation, insistent, rw95, visualise, irony, resented, laughter, annoyance, warned, haughtiness, kd96, reflecting, dejected, seeming, hypocritical, alienation, sullen, dismayed, bizarre, remembered, maelstrom, status, reason, airiness, wondering, unconvincing, help, tradition, suspenseful, marvelous, attentiveness, drudgery, demoralizing, shields, brought, pain, defeats, wisdom, oddness, frenzy, camphor, frantic, acknowledging, epically, sinicization, evident, proclivity, compounded, treating, seething, denouncement, jitters, skylarking, unease, weariness, scandalous, furor, look, turn, unfocused, fascinated, reassurances, appalled, bad, 28aou94, incredibly, riveting, concern, uplifting, bemoan, amorality, detractors, parents, revelatory, despair, k587-1, gleeful, groggy, anticipating, calling, greatness, anticipation, firecrackers, expressed, menacing, generalise, treachery, splendid, squeamish, supplant, palpable, hope, painstaking, lightheadedness, lanterns, smugness, reproach, prosecuted, frankincense, votive, idealize, trivialize, swoon, disaster, equated, frightening, alarmed, backlash, tiredness, blurbed, fluctuate, bruising, error-prone, candles, excited, delights, lifeline, sweating, rallying, burning, teargas, insinuation, cackles, wary, purposefulness, hypocrisy, experience, unfortunately, value, stabiliser, clamoring, whatever, achievement, agitate, feature, turning, miserable, accustomed, ethereal, ascribe, bringing, complacent, rates, drubbing, expecting, villainy, powerless, overdressed, sick, pretty, humility, live-action, perfidy, mothers, fixated, dullness, true, glad, wanting, uncharacteristic, mystified, sort, overconfidence, alabamians, affection, js03, need, devaluating, hesitancy, demonstrates, felicitously, believers, fact, shrewdness, displeased, immediate, dispatched, libations, nausea, hesitant, hurry, delight, vigilant, hopeful, sorrowfully, triumph, increasing, thermoregulation, dislike, dreamworks, interesting, come, scented, disheartened, exhausting, emotionalism, cries, helping, paranoia, devaluate, exhilaration, likening, liberality, ambivalent, delightful, fatigued, lending, enthusiasm, mocked, despairing, fascination, afraid, pretentiousness, beenz, dazzling, grace, washingtonians, attitude, protesters, engaging, disgust, mims, intrigued, vituperation, responding, cheered, claustrophobia, throngs, significance, betrayal, voluptuousness, injustice, plaudits, stunned, uninterested, fearing, thoughtfulness, conscience, dumbstruck, uncertainty, preoccupation, admitting, ..., inspiration, stones, nonchalance, constricted, betrayed, http://www.nifc.gov/, chance, disliked, solid, soothing, calmed, prompts, nonplussed, invective, visuals, disgusted, obsession, approbation, euphoric, frankly, thrilling, disperse, swings, shadows, provoked, manoeuvre, obviously, inviting, mercy, regretful, recognizes, elated, unquestionable, accuse, adventurousness, ought, blaming, moreover, marvellous, hardly, re-visited, fascinating, grandiosity, equal, stunning, gloom, zeal, actions, ominous, bring, relief, certainly, protectiveness, disgraceful, lament, inability, mendacity, disinterest, dejection, piety, miffed, expectations, reticent, apotheosis, offering, symbolize, admired, grief, votives, interest, .0208, weekend, shelter, displeasing, temperament, animators, disturbing, outrage, admire, nostalgia, hatter, nowadays, debauchery, loved, restless, acceptance, respecting, migraines, shyness, cheers, enigmatically, ghastly, unleashed, respects, borrowing, similarly, derision, compensators, enjoys, detest, astonishment, strongly, wicked, admirable, implying, envy, ironic, panicked, action-packed, dehumanization, compassion, abhorred, diarrhea, unfairness, distasteful, suffering, nosebleeds, deform, ingenuous, enchanting, torturous, shamefaced, burst, broken, bitterness, beeswax, contrition, spooked, repentance, decent, dissapointed, ignoring, dizziness, temper, optimistic, humiliated, sadness, guiltily, joke, wondrous, endearing, misunderstand, humaneness, crystallise, visual, denunciation, doctrine, brokenhearted, catcalls, wafted, str95bb, applaud, seductive, ignore, scary, opprobrium, affectations, nightmare, ambition, alerting, proclivities, neediness, formulaic, wearying, http://www.opel.com, proud, simply, ill-founded, occasion, afflicted, bereft, vivacity, inquisitive, playfulness, cleverness, pleasantness, lucidity, signified, maneuverability, naborsind, engrossing, bafflement, disenchantment, buoyancy, 3-d, breathless, sight, virtue, discontent, viciousness, scornful, courtesy, rioters, irreverence, jaundice, kalamity, chagrin, shamed, saw, coldness, believe, youthfulness, angry, malaise, conviction, talky, dreams, besides, excitement, fatigue, embarrassing, warrant, thunderstruck, cacophony, uselessness, forsake, suggestion, melancholic, brave, awestruck, animation, latest, ethos, feelings, overanalyze, obstinate, precaution, irritation, denigration, failure, dishonour, shrilly, signal, regrets, shout, diffident, confident, mortifying, crazy, uncertain, upon, .0202, apologise, propensity, bdb94, check, animator, rashes, slovenliness, comfy, orderliness, laziness, gph04bb, grenades, unconcerned, doubt, treated, recognising, skyrocket, recklessness, sanguine, fabulousness, frustrating, disillusion, vulnerable, theatricality, folks, revulsion, upbeat, euphoria, fretful, equanimity, spend, time-consuming, worse, invigorating, uninitiated, omission, surliness, hungry, distraction, depreciates, envious, panache, humanitarian, reconstruction, ardour, going, spirit, blamed, disdain, sticks, lit, edgy, asserting, transference, simple-minded, familiarity, piyanart, deflate, remarkable, bravado, explain, resent, enlightening, achieved, peculiar, jumpy, achievements, consternation, surreal, snobbery, reluctance, david.lazarus@latimes.com, indignation, commitment, hoped, lambasting, reflected, friendliness, exuberant, twitchy, defiance, testifying, emotions, exasperation, aback, surveillance, discomfiting, evocation, distracted, everyone, oftentimes, mind, threats, mocks, rebukes, participation, regard, magnanimity, cautiously, apprehensive, befuddled, wonderment, emergency, falseness, exhilarating, contend, filmmaking, awkward, wishes, blunt, hopeless, haunting, ill-informed, rectitude, propitiation, heaped, cynicism, noticed, enjoyed, forcefulness, batons, mania, loathing, eloquence, sorrowful, clear, mockery, indifference, predictably, dismaying, profess, pranked, shock, introspective, efforts, incredulity, ignorance, longing, castigation, horrifying, inscrutably, insipid, enjoying, stun, radiance, nor, doubles_biggio, misery, reprisal, anticipate, imagine, quietude, sparklers, calamitous, disregard, despised, amazed, rootlessness, belief, downsize, firebombs, reassuring, despondent, vulnerability, realizing, symptoms, ingratitude, disorienting, rattled, entranced, fondness, dubbed, inconstancy, selflessness, antagonism, ill, forgiveness, appreciating, tendency, menace, coded, contingent, x.xx.xx.xx.x, unflustered, give, despise, counteract, restlessness, warnings, .000088, vengeful, stupid, grotesque, upset, hoping, find, perturb, constipation, current, messy, k978-1, cuteness, flummoxed, questioning, fatuous, sickness, longevity, kid, insomnia, judgment, sandalwood, unseemly, dignity, aimlessness, believes, marveled, mishandle, dishonesty, advocation, stoicism, ire, elaboration, determined, embittered, concerns, underwhelmed, babies, gratitude, keep, aid, action, alerted, anguish, inclusion, inflexibility, depreciate, disrespect, disgrace, brashness, flustered, staggering, dreadful, thankful, mortified, postmodernists, lopsided, blandness, townsfolk, hilarity, calumny, slander, assured, burners, …, disillusionment, avoid, stupidity, although, exhortation, peppermints, decry, engendering, candor, understand, loath, pervading, unlikely, idiosyncrasy, loyalty, rebuilding, despite, shocking, offended, thanks, hysteria, soulfulness, beliefs, overconfident, unnerved, fury, complain, angered, depletes, tear, crispness, leave, unexpected, intimidated, soon, anti-clericalism, kd97, baffled, mtow, astonished, retaliation, absurdity, unconvinced, multimedia, hipness, denunciations, predilection, interpenetration, bhagya, liberty, unprepared, happiness, everybody, confidence, heartbroken, jealousy, booing, nastiness, legitimacy, heartlessness, malevolent, rollicking, timidity, tiresome, disbelief, curses, suggesting, desire, jolting\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "\", \".join(vocabulary_expanded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdlrgIohRKIG"
      },
      "source": [
        "Algumas palavras podem não estar relacionadas à emoção, porém, o método de aprendizado de máquina ainda é capaz de considerar palavras mais relevantes para uma determinada instancia, ignorando algum ruído. Veja como ficou a representação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2w3d9RJ0RKIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "724bacb4-3b4a-4398-a983-f12d0130d53d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             bad  canister  disappointed  experience      fact  fascinating  \\\n",
              "id                                                                            \n",
              "208138  0.000000  0.000000      0.000000    0.606043  0.000000     0.000000   \n",
              "157010  0.000000  0.000000      0.000000    0.000000  0.490297     0.490297   \n",
              "101657  0.000000  0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "49225   0.000000  0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "158265  0.000000  0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "204215  0.000000  0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "274316  0.606043  0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "57708   0.000000  0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "200048  0.000000  0.707107      0.707107    0.000000  0.000000     0.000000   \n",
              "60933   0.000000  0.000000      0.000000    0.000000  0.000000     0.000000   \n",
              "\n",
              "        find      give  god      good  ...       put   putting     sense  \\\n",
              "id                                     ...                                 \n",
              "208138   0.0  0.606043  0.0  0.000000  ...  0.000000  0.515192  0.000000   \n",
              "157010   0.0  0.000000  0.0  0.324199  ...  0.416798  0.000000  0.000000   \n",
              "101657   0.0  0.000000  0.0  1.000000  ...  0.000000  0.000000  0.000000   \n",
              "49225    0.0  0.000000  0.0  0.551556  ...  0.000000  0.000000  0.000000   \n",
              "158265   0.0  0.000000  0.5  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "204215   0.0  0.000000  0.0  0.000000  ...  0.515192  0.000000  0.606043   \n",
              "274316   0.0  0.000000  0.0  0.000000  ...  0.000000  0.515192  0.000000   \n",
              "57708    0.5  0.000000  0.0  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "200048   0.0  0.000000  0.0  0.000000  ...  0.000000  0.000000  0.000000   \n",
              "60933    0.0  0.000000  0.0  0.313903  ...  0.000000  0.000000  0.000000   \n",
              "\n",
              "        sick  sympathetic      true     video  wanting     worse     class  \n",
              "id                                                                          \n",
              "208138   0.0          0.0  0.000000  0.000000      0.0  0.000000  positive  \n",
              "157010   0.0          0.0  0.000000  0.000000      0.0  0.000000  positive  \n",
              "101657   0.0          0.0  0.000000  0.000000      0.0  0.000000  positive  \n",
              "49225    0.0          0.0  0.000000  0.000000      0.0  0.000000  positive  \n",
              "158265   0.0          0.0  0.000000  0.000000      0.5  0.000000  positive  \n",
              "204215   0.0          0.0  0.000000  0.000000      0.0  0.000000  negative  \n",
              "274316   0.0          0.0  0.000000  0.000000      0.0  0.606043  negative  \n",
              "57708    0.5          0.5  0.000000  0.000000      0.0  0.000000  negative  \n",
              "200048   0.0          0.0  0.000000  0.000000      0.0  0.000000  negative  \n",
              "60933    0.0          0.0  0.474727  0.474727      0.0  0.000000  negative  \n",
              "\n",
              "[10 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b867c5e1-d18c-4d8a-be1f-1b72fb97e117\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bad</th>\n",
              "      <th>canister</th>\n",
              "      <th>disappointed</th>\n",
              "      <th>experience</th>\n",
              "      <th>fact</th>\n",
              "      <th>fascinating</th>\n",
              "      <th>find</th>\n",
              "      <th>give</th>\n",
              "      <th>god</th>\n",
              "      <th>good</th>\n",
              "      <th>...</th>\n",
              "      <th>put</th>\n",
              "      <th>putting</th>\n",
              "      <th>sense</th>\n",
              "      <th>sick</th>\n",
              "      <th>sympathetic</th>\n",
              "      <th>true</th>\n",
              "      <th>video</th>\n",
              "      <th>wanting</th>\n",
              "      <th>worse</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>208138</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.606043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.606043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.515192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157010</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490297</td>\n",
              "      <td>0.490297</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.324199</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416798</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101657</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49225</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.551556</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158265</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204215</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.515192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.606043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274316</th>\n",
              "      <td>0.606043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.515192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.606043</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57708</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200048</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60933</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.313903</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.474727</td>\n",
              "      <td>0.474727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b867c5e1-d18c-4d8a-be1f-1b72fb97e117')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b867c5e1-d18c-4d8a-be1f-1b72fb97e117 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b867c5e1-d18c-4d8a-be1f-1b72fb97e117');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cfcf55d1-aed7-44e1-a197-cc54d3b8cf5a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfcf55d1-aed7-44e1-a197-cc54d3b8cf5a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cfcf55d1-aed7-44e1-a197-cc54d3b8cf5a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "bag_of_words(df_amazon_mini,vocabulary_expanded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xveUuaWMRKIG"
      },
      "source": [
        "Poderiamos agrupar as palavras chaves em conceitos, por exemplo, \"happiness\" ser sempre contabilizado quando houver um conjunto de palavras, por exemplo, '\"joy\",\"cheer\", \"bliss\", \"delight\", \"enjoy\", \"happy\"'. Porém, isso pode restringir muito o número de palavras e expandir com palavras usando embeddings, pode extrair palavras relacionadas com a emoção oposta (veja exemplo abaixo). Por isso, optamos por apresentar a representação usando bag of words. Mesmo assim, caso queira ver algum resultado dessa forma, a classe CountWords implementa expansão por grupos de palavras chaves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "w3TDXLKiRKIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6ce5fc66-50c6-49bc-94c0-26a12793b546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"happy, feel, glad, sure, everyone, 'm, definitely, 'd, 'll, remember, everybody, wish, proud, 're, really, always, maybe, excited, good, lucky, obviously, thrilled, pleased, pretty, wonderful, know, afraid, delighted, looking, want, thing, imagine, think, unhappy, satisfied, realize, knowing, going, tired, crazy\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\n",
        "distance, words = kdtree_embedding.get_most_similar_embedding(\"happy\",40)\n",
        "#veja que unhappy é relacionado com happy - além de outras palavras negativas e ruido\n",
        "\", \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dSaY_ZHsrOv",
        "outputId": "d05d9626-4d73-4b53-b8fa-e82febde5d67"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5qMBM_GxRKIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "5f3d4267-968c-4f35-f3bb-6dabf041b763"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        pride  elation  happiness  satisfaction  relief  hope  interest  \\\n",
              "208138      0        0         14             0       0     7         0   \n",
              "157010      0        0          5             0       0     5         2   \n",
              "101657      0        0          7             0       0     5         0   \n",
              "49225       0        0          4             0       0     3         0   \n",
              "158265      0        0          3             0       0     1         0   \n",
              "204215      0        0          0             0       0     1         0   \n",
              "274316      0        0          2             0       0     0         0   \n",
              "57708       0        0         10             0       0     7         0   \n",
              "200048      0        0          4             0       0     2         0   \n",
              "60933       0        0         12             0       0     2         0   \n",
              "\n",
              "        surprise  anxiety  sadness  boredom  shame  guilt  disgust  contempt  \\\n",
              "208138         0        4        0        0      0      0        0         0   \n",
              "157010         0        3        0        0      0      0        0         0   \n",
              "101657         0        0        0        0      0      0        0         0   \n",
              "49225          0        1        0        0      0      0        0         0   \n",
              "158265         0        1        0        0      0      0        0         0   \n",
              "204215         0        1        0        0      0      0        0         0   \n",
              "274316         0        0        0        0      0      0        0         0   \n",
              "57708          0        5        0        0      0      0        1         0   \n",
              "200048         0        0        0        0      0      0        0         0   \n",
              "60933          0       12        1        0      0      0        0         0   \n",
              "\n",
              "        hostile  anger  recognition     class  \n",
              "208138        0      0            0  positive  \n",
              "157010        0      0            0  positive  \n",
              "101657        0      0            1  positive  \n",
              "49225         0      0            0  positive  \n",
              "158265        0      0            0  positive  \n",
              "204215        0      0            0  negative  \n",
              "274316        0      0            0  negative  \n",
              "57708         0      0            0  negative  \n",
              "200048        0      0            0  negative  \n",
              "60933         0      0            0  negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1667eb6-0677-43f9-8cf8-2a0a8ba716d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pride</th>\n",
              "      <th>elation</th>\n",
              "      <th>happiness</th>\n",
              "      <th>satisfaction</th>\n",
              "      <th>relief</th>\n",
              "      <th>hope</th>\n",
              "      <th>interest</th>\n",
              "      <th>surprise</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>sadness</th>\n",
              "      <th>boredom</th>\n",
              "      <th>shame</th>\n",
              "      <th>guilt</th>\n",
              "      <th>disgust</th>\n",
              "      <th>contempt</th>\n",
              "      <th>hostile</th>\n",
              "      <th>anger</th>\n",
              "      <th>recognition</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>208138</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157010</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101657</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49225</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158265</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204215</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274316</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57708</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200048</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60933</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1667eb6-0677-43f9-8cf8-2a0a8ba716d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1667eb6-0677-43f9-8cf8-2a0a8ba716d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1667eb6-0677-43f9-8cf8-2a0a8ba716d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8f8cff0-6016-4fb9-85d8-af54334eb5ca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8f8cff0-6016-4fb9-85d8-af54334eb5ca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8f8cff0-6016-4fb9-85d8-af54334eb5ca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from embeddings.textual_representation import CountWords,InstanceWisePreprocess\n",
        "aggregate = CountWords(dict_embedding, emotion_words,max_distance=0.3)\n",
        "\n",
        "word_counter = InstanceWisePreprocess(\"word-counter\",aggregate)\n",
        "word_counter.preprocess_train_dataset(df_amazon_mini, \"class\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI_Ur5rYRKIG"
      },
      "source": [
        "O max_distance é responsável por obter as palavras similares. Veja que diversos documentos negativos foram classificados com o grupo \"happiness\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm_efCsFRKIG"
      },
      "source": [
        "**Representação agregando embeddings das palavras:** Conforme proposto por [Shen et al.](https://arxiv.org/pdf/1805.09843.pdf), dado que uma frase é representado por um conjunto de embeddings $\\{e_1, e_2, ..., e_n\\}$  uma forma simples e que geralmente obtém resultados **comparáveis a métodos mais complexos** é fazer operações em cada dimensão do embedding, tais como: média e máximo por dimensão do embedding. Por exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "A2nVdxxnRKIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fd2328-4568-49c7-b76c-a6dd30c0b2b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'house', 'is', 'green']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#embeddings de alguams palavras:\n",
        "dict_embedding = {'my':      [10, 11,14, 20, 15, 80],\n",
        "                  'house':   [11, 12,10, 24, 11, 30],\n",
        "                  'is':      [1,  3,  5, -1, 10, 20],\n",
        "                  'green':   [12,10, 20, 12, 10, 20]\n",
        "                   }\n",
        "#representação do texto \"my house is green\"\n",
        "arr_texto = \"my house is green\".split()\n",
        "arr_texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oVJiIJ0RKIH"
      },
      "source": [
        "**Usando a média de cada dimensão dos embeddings:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "931YjKQyRKIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9d2af8-b7d5-489d-e2e0-7707da8bc63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representação: [8.5, 9.0, 12.25, 13.75, 11.5, 37.5]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def average_pooling(arr_texto, dim_embedding):\n",
        "    representacao = []\n",
        "    for i in range(dim_embedding):\n",
        "        #calcula a média da iésima posição do embedding\n",
        "        sum_pos = 0\n",
        "        for word in arr_texto:\n",
        "            sum_pos += dict_embedding[word][i]\n",
        "\n",
        "        representacao.append(sum_pos/len(arr_texto))\n",
        "    return representacao\n",
        "dim_embedding = 6\n",
        "representacao = average_pooling(arr_texto, dim_embedding)\n",
        "print(f\"Representação: {representacao}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oej-PVVGRKIH"
      },
      "source": [
        "**Usando o máximo de cada dimensão dos embeddings:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nrWW7V9PRKII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b807493b-ba60-4c65-ac2f-71915c025341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representação: [12, 12, 20, 24, 15, 80]\n"
          ]
        }
      ],
      "source": [
        "dim_embedding = 6\n",
        "def max_pooling(arr_texto, dim_embedding):\n",
        "    representacao = []\n",
        "    for i in range(dim_embedding):\n",
        "        #calcula o valor máximo de cada iésima posição do embedding\n",
        "        first_word = arr_texto[0]\n",
        "        max_pos = dict_embedding[first_word][i]\n",
        "        for word in arr_texto[1:]:\n",
        "            if max_pos < dict_embedding[word][i]:\n",
        "                max_pos = dict_embedding[word][i]\n",
        "\n",
        "        representacao.append(max_pos)\n",
        "    return representacao\n",
        "representacao = max_pooling(arr_texto, dim_embedding)\n",
        "print(f\"Representação: {representacao}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4og5N7LRRKII"
      },
      "source": [
        "Como há palavras pouco relevantes (como stopwords) podemos remove-las e, também podemos utilizar apenas as palavras de um vocabulario controlado. Abaixo veja a representação. Como esta representação é vetorial, a mesma não é uma representação simples de ser entendida por humanos, porém, pode-se obter bons resultados. Você pode adicionar o vocabulario controlado ou as stopwords por meio dos parametros correpondentes. O parâmetro `aggregate_method` define se será feito um maximo ou média entre os embeddings colocando os valores `max` ou `avg`, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HZEcQbAnRKII",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cedc7f26-26db-4742-effe-0a3133cd8ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: the\n",
            "10000: persecution\n",
            "20000: baths\n",
            "30000: mortally\n",
            "40000: 1667\n",
            "50000: bec\n",
            "60000: baek\n",
            "70000: b/w\n",
            "80000: klinghoffer\n",
            "90000: azarov\n",
            "100000: capron\n",
            "110000: perpetua\n",
            "120000: biratnagar\n",
            "130000: 12.74\n",
            "140000: yaffa\n",
            "150000: cryogenics\n",
            "160000: ef1\n",
            "170000: franchetti\n",
            "180000: blintzes\n",
            "190000: birthstones\n",
            "200000: naadam\n",
            "210000: concertation\n",
            "220000: lesticus\n",
            "230000: containerboard\n",
            "240000: boydston\n",
            "250000: afterellen.com\n",
            "260000: acuff-rose\n",
            "270000: close-fitting\n",
            "280000: packbot\n",
            "290000: comptel\n",
            "300000: tanke\n",
            "310000: saraju\n",
            "320000: rouiba\n",
            "330000: discomfit\n",
            "340000: numurkah\n",
            "350000: hla-a\n",
            "360000: 90125\n",
            "370000: zipkin\n",
            "380000: lombarde\n",
            "390000: 1.137\n",
            "Palavras ignoradas: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0         1         2         3         4         5         6  \\\n",
              "208138 -0.059204  0.191895  0.372070  0.126587 -0.102600 -0.024734 -0.340088   \n",
              "157010 -0.064270  0.268555  0.395020 -0.094360 -0.176514  0.011276 -0.220093   \n",
              "101657 -0.030762  0.119934  0.539062 -0.437012 -0.739258 -0.153442  0.081116   \n",
              "49225  -0.127930  0.394287  0.441895 -0.243408 -0.411377 -0.300293  0.028076   \n",
              "158265  0.449951  0.435547  0.288086 -0.087097 -0.048950  0.714844 -0.627441   \n",
              "204215  0.040314  0.040253  0.532227 -0.346191 -0.253418  0.219482 -0.346924   \n",
              "274316  0.158936 -0.016418  0.793945 -0.266113 -0.669434 -0.004871 -0.398193   \n",
              "57708   0.162231  0.439941  0.299561 -0.111328 -0.139404  0.153687 -0.460449   \n",
              "200048 -0.154175  0.127686  0.332520 -0.328125 -0.582031  0.210815  0.188110   \n",
              "60933  -0.006786  0.071411  0.483154 -0.466309 -0.287598  0.137451 -0.036652   \n",
              "\n",
              "               7         8         9  ...        91        92        93  \\\n",
              "208138  0.083252 -0.264160 -0.224731  ... -0.258545  0.219971 -0.457031   \n",
              "157010 -0.191528 -0.177979 -0.433350  ... -0.135132  0.084656 -0.274170   \n",
              "101657 -0.385498 -0.687988 -0.416260  ... -0.440430  0.083313  0.200317   \n",
              "49225  -0.054688 -0.478516 -0.224731  ... -0.283691  0.092102 -0.050598   \n",
              "158265 -0.139526  0.037781 -0.392822  ... -0.330322  0.201050  0.036438   \n",
              "204215 -0.459229 -0.234009 -0.016251  ... -0.179688  0.093750 -0.037048   \n",
              "274316 -0.331055  0.040588 -0.129272  ... -0.127441 -0.073242 -0.206665   \n",
              "57708  -0.149048  0.320801 -0.473389  ... -0.045044  0.411377 -0.177979   \n",
              "200048  0.594238  0.397949  0.190674  ... -0.284912 -0.298096 -0.150879   \n",
              "60933   0.012230 -0.068115 -0.241211  ...  0.056396  0.058685  0.099060   \n",
              "\n",
              "              94        95        96        97        98        99     class  \n",
              "208138 -0.332764 -0.326172 -0.164795 -0.160400  0.378906  0.456543  positive  \n",
              "157010 -0.524414 -0.061218 -0.264160 -0.521973  0.185547  0.541992  positive  \n",
              "101657 -0.754883  0.169189 -0.265625 -0.528809  0.175781  1.065430  positive  \n",
              "49225  -0.695801  0.098633  0.142578 -0.408447  0.257324  0.741699  positive  \n",
              "158265 -0.448730 -0.454346 -0.360840 -0.517578  0.019989  0.399902  positive  \n",
              "204215 -0.417480 -0.152466  0.052826 -0.471924  0.008827  0.480225  negative  \n",
              "274316 -0.333496  0.056488  0.071777  0.239014  0.317383 -0.004375  negative  \n",
              "57708  -0.549805 -0.000109 -0.155273 -0.111450  0.056763  0.045990  negative  \n",
              "200048  0.051758  0.336914  0.061096  0.478516 -0.390137  0.254883  negative  \n",
              "60933  -0.135742 -0.311035 -0.453125 -0.349121  0.174072  0.460205  negative  \n",
              "\n",
              "[10 rows x 101 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8683af38-85ec-45d6-a213-75d9cf8c312b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>208138</th>\n",
              "      <td>-0.059204</td>\n",
              "      <td>0.191895</td>\n",
              "      <td>0.372070</td>\n",
              "      <td>0.126587</td>\n",
              "      <td>-0.102600</td>\n",
              "      <td>-0.024734</td>\n",
              "      <td>-0.340088</td>\n",
              "      <td>0.083252</td>\n",
              "      <td>-0.264160</td>\n",
              "      <td>-0.224731</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.258545</td>\n",
              "      <td>0.219971</td>\n",
              "      <td>-0.457031</td>\n",
              "      <td>-0.332764</td>\n",
              "      <td>-0.326172</td>\n",
              "      <td>-0.164795</td>\n",
              "      <td>-0.160400</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.456543</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157010</th>\n",
              "      <td>-0.064270</td>\n",
              "      <td>0.268555</td>\n",
              "      <td>0.395020</td>\n",
              "      <td>-0.094360</td>\n",
              "      <td>-0.176514</td>\n",
              "      <td>0.011276</td>\n",
              "      <td>-0.220093</td>\n",
              "      <td>-0.191528</td>\n",
              "      <td>-0.177979</td>\n",
              "      <td>-0.433350</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.135132</td>\n",
              "      <td>0.084656</td>\n",
              "      <td>-0.274170</td>\n",
              "      <td>-0.524414</td>\n",
              "      <td>-0.061218</td>\n",
              "      <td>-0.264160</td>\n",
              "      <td>-0.521973</td>\n",
              "      <td>0.185547</td>\n",
              "      <td>0.541992</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101657</th>\n",
              "      <td>-0.030762</td>\n",
              "      <td>0.119934</td>\n",
              "      <td>0.539062</td>\n",
              "      <td>-0.437012</td>\n",
              "      <td>-0.739258</td>\n",
              "      <td>-0.153442</td>\n",
              "      <td>0.081116</td>\n",
              "      <td>-0.385498</td>\n",
              "      <td>-0.687988</td>\n",
              "      <td>-0.416260</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.440430</td>\n",
              "      <td>0.083313</td>\n",
              "      <td>0.200317</td>\n",
              "      <td>-0.754883</td>\n",
              "      <td>0.169189</td>\n",
              "      <td>-0.265625</td>\n",
              "      <td>-0.528809</td>\n",
              "      <td>0.175781</td>\n",
              "      <td>1.065430</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49225</th>\n",
              "      <td>-0.127930</td>\n",
              "      <td>0.394287</td>\n",
              "      <td>0.441895</td>\n",
              "      <td>-0.243408</td>\n",
              "      <td>-0.411377</td>\n",
              "      <td>-0.300293</td>\n",
              "      <td>0.028076</td>\n",
              "      <td>-0.054688</td>\n",
              "      <td>-0.478516</td>\n",
              "      <td>-0.224731</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.283691</td>\n",
              "      <td>0.092102</td>\n",
              "      <td>-0.050598</td>\n",
              "      <td>-0.695801</td>\n",
              "      <td>0.098633</td>\n",
              "      <td>0.142578</td>\n",
              "      <td>-0.408447</td>\n",
              "      <td>0.257324</td>\n",
              "      <td>0.741699</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158265</th>\n",
              "      <td>0.449951</td>\n",
              "      <td>0.435547</td>\n",
              "      <td>0.288086</td>\n",
              "      <td>-0.087097</td>\n",
              "      <td>-0.048950</td>\n",
              "      <td>0.714844</td>\n",
              "      <td>-0.627441</td>\n",
              "      <td>-0.139526</td>\n",
              "      <td>0.037781</td>\n",
              "      <td>-0.392822</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.330322</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.036438</td>\n",
              "      <td>-0.448730</td>\n",
              "      <td>-0.454346</td>\n",
              "      <td>-0.360840</td>\n",
              "      <td>-0.517578</td>\n",
              "      <td>0.019989</td>\n",
              "      <td>0.399902</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204215</th>\n",
              "      <td>0.040314</td>\n",
              "      <td>0.040253</td>\n",
              "      <td>0.532227</td>\n",
              "      <td>-0.346191</td>\n",
              "      <td>-0.253418</td>\n",
              "      <td>0.219482</td>\n",
              "      <td>-0.346924</td>\n",
              "      <td>-0.459229</td>\n",
              "      <td>-0.234009</td>\n",
              "      <td>-0.016251</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.179688</td>\n",
              "      <td>0.093750</td>\n",
              "      <td>-0.037048</td>\n",
              "      <td>-0.417480</td>\n",
              "      <td>-0.152466</td>\n",
              "      <td>0.052826</td>\n",
              "      <td>-0.471924</td>\n",
              "      <td>0.008827</td>\n",
              "      <td>0.480225</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274316</th>\n",
              "      <td>0.158936</td>\n",
              "      <td>-0.016418</td>\n",
              "      <td>0.793945</td>\n",
              "      <td>-0.266113</td>\n",
              "      <td>-0.669434</td>\n",
              "      <td>-0.004871</td>\n",
              "      <td>-0.398193</td>\n",
              "      <td>-0.331055</td>\n",
              "      <td>0.040588</td>\n",
              "      <td>-0.129272</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.127441</td>\n",
              "      <td>-0.073242</td>\n",
              "      <td>-0.206665</td>\n",
              "      <td>-0.333496</td>\n",
              "      <td>0.056488</td>\n",
              "      <td>0.071777</td>\n",
              "      <td>0.239014</td>\n",
              "      <td>0.317383</td>\n",
              "      <td>-0.004375</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57708</th>\n",
              "      <td>0.162231</td>\n",
              "      <td>0.439941</td>\n",
              "      <td>0.299561</td>\n",
              "      <td>-0.111328</td>\n",
              "      <td>-0.139404</td>\n",
              "      <td>0.153687</td>\n",
              "      <td>-0.460449</td>\n",
              "      <td>-0.149048</td>\n",
              "      <td>0.320801</td>\n",
              "      <td>-0.473389</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045044</td>\n",
              "      <td>0.411377</td>\n",
              "      <td>-0.177979</td>\n",
              "      <td>-0.549805</td>\n",
              "      <td>-0.000109</td>\n",
              "      <td>-0.155273</td>\n",
              "      <td>-0.111450</td>\n",
              "      <td>0.056763</td>\n",
              "      <td>0.045990</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200048</th>\n",
              "      <td>-0.154175</td>\n",
              "      <td>0.127686</td>\n",
              "      <td>0.332520</td>\n",
              "      <td>-0.328125</td>\n",
              "      <td>-0.582031</td>\n",
              "      <td>0.210815</td>\n",
              "      <td>0.188110</td>\n",
              "      <td>0.594238</td>\n",
              "      <td>0.397949</td>\n",
              "      <td>0.190674</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.284912</td>\n",
              "      <td>-0.298096</td>\n",
              "      <td>-0.150879</td>\n",
              "      <td>0.051758</td>\n",
              "      <td>0.336914</td>\n",
              "      <td>0.061096</td>\n",
              "      <td>0.478516</td>\n",
              "      <td>-0.390137</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60933</th>\n",
              "      <td>-0.006786</td>\n",
              "      <td>0.071411</td>\n",
              "      <td>0.483154</td>\n",
              "      <td>-0.466309</td>\n",
              "      <td>-0.287598</td>\n",
              "      <td>0.137451</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>0.012230</td>\n",
              "      <td>-0.068115</td>\n",
              "      <td>-0.241211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056396</td>\n",
              "      <td>0.058685</td>\n",
              "      <td>0.099060</td>\n",
              "      <td>-0.135742</td>\n",
              "      <td>-0.311035</td>\n",
              "      <td>-0.453125</td>\n",
              "      <td>-0.349121</td>\n",
              "      <td>0.174072</td>\n",
              "      <td>0.460205</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 101 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8683af38-85ec-45d6-a213-75d9cf8c312b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8683af38-85ec-45d6-a213-75d9cf8c312b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8683af38-85ec-45d6-a213-75d9cf8c312b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b10706b-dba8-4764-b29e-091e9d57f590\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b10706b-dba8-4764-b29e-091e9d57f590')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b10706b-dba8-4764-b29e-091e9d57f590 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "#obtem as stopwords\n",
        "stop_words = set()\n",
        "with open(\"datasets/stopwords.txt\") as stop_file:\n",
        "    stop_words = set(stop_word[:-1] for stop_word in stop_file)\n",
        "\n",
        "from embeddings.textual_representation import AggregateEmbeddings,InstanceWisePreprocess\n",
        "dict_embedding = get_embedding(\"glove.en.100.txt\")\n",
        "aggregate_keywords_exp = AggregateEmbeddings(dict_embedding, aggregate_method=\"avg\",\n",
        "                                            words_to_filter=stop_words, words_to_consider=vocabulary_expanded)\n",
        "emb_keywords_exp = InstanceWisePreprocess(\"emb_keywords_exp\",aggregate_keywords_exp)\n",
        "emb_keywords_exp.preprocess_train_dataset(df_amazon_mini, \"class\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR0N9EcsRKII"
      },
      "source": [
        "## Avaliação por meio de um método de aprendizado de máquina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5tvGBD0RKII"
      },
      "source": [
        "Os embeddings podem oferecer uma informação de proximidade de conceitos que o uso de Bag of Words não seria capaz. Mesmo assim, cada representação e preprocessamento tem sua vantagem e desvantagem e não existe um método que será sempre o melhor. Assim, para sabermos qual representação é melhor para uma tarefa, é importante avaliarmos em quais delas são maiores para a tarefa em questão. Como o foco desta prática não é a avaliação, iremos apenas apresentar o resultado, caso queira, você pode [assistir a video aula](https://www.youtube.com/watch?v=Ag06UuWTsr4&list=PLwIaU1DGYV6tUx10fCTw5aPnqypbbK_GJ&index=12) e [fazer a prática sobre avaliação](https://github.com/daniel-hasan/ap-de-maquina-cefetmg-avaliacao/archive/master.zip). Nesta parte, iremos apenas usar a avaliação para verificar qual método é melhor.  \n",
        "\n",
        "Para que esta seção seja auto contida, iremos fazer toda a preparação que fizemos nas seções anteriores\n",
        "\n",
        "**Criação da lista de stopwords e de vocabulário:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "YX1QcMQBRKIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5207bec6-8bb4-41ae-be1e-9ffae36c49ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: the\n",
            "10000: persecution\n",
            "20000: baths\n",
            "30000: mortally\n",
            "40000: 1667\n",
            "50000: bec\n",
            "60000: baek\n",
            "70000: b/w\n",
            "80000: klinghoffer\n",
            "90000: azarov\n",
            "100000: capron\n",
            "110000: perpetua\n",
            "120000: biratnagar\n",
            "130000: 12.74\n",
            "140000: yaffa\n",
            "150000: cryogenics\n",
            "160000: ef1\n",
            "170000: franchetti\n",
            "180000: blintzes\n",
            "190000: birthstones\n",
            "200000: naadam\n",
            "210000: concertation\n",
            "220000: lesticus\n",
            "230000: containerboard\n",
            "240000: boydston\n",
            "250000: afterellen.com\n",
            "260000: acuff-rose\n",
            "270000: close-fitting\n",
            "280000: packbot\n",
            "290000: comptel\n",
            "300000: tanke\n",
            "310000: saraju\n",
            "320000: rouiba\n",
            "330000: discomfit\n",
            "340000: numurkah\n",
            "350000: hla-a\n",
            "360000: 90125\n",
            "370000: zipkin\n",
            "380000: lombarde\n",
            "390000: 1.137\n",
            "Palavras ignoradas: 0\n"
          ]
        }
      ],
      "source": [
        "from embeddings.utils import get_embedding, KDTreeEmbedding\n",
        "\n",
        "emotion_words = {\n",
        "                    \"pride\":{\"proud\"},\n",
        "                    \"elation\":{\"ecstatic\", \"euphoria\", \"exaltation\", \"exhilarating\"},#vs boredom\n",
        "                    \"happiness\":{\"joy\",\"cheer\", \"bliss\", \"delight\", \"enjoy\", \"happy\"},#vs sad\n",
        "                    \"satisfaction\":{\"comfortable\",\"contentment\"},#\n",
        "                    \"relief\":{},\n",
        "                    \"hope\":{\"buoyancy\", \"confident\", \"faith\", \"optimistic\"},\n",
        "                    \"interest\":{\"alert\", \"animation\", \"ardor\", \"curious\",\"enthusiasm\"},\n",
        "                    \"surprise\":{\"amazed\", \"astonishing\", \"dumbfounded\",\"thunderstruck\"},\n",
        "                    \"anxiety\":{\"anguish\",\"anxiety\",\"apprehensive\",\"jittery\",\"nervous\",\"worry\"},\n",
        "                    \"sadness\":{\"chagrin\", \"dejected\", \"gloom\", \"hopeless\", \"melancholy\", \"sad\", \"tear\"},\n",
        "                    \"boredom\":{\"ennui\",\"indifference\",\"tedious\"},\n",
        "                    \"shame\":{\"abashed\", \"ashamed\", \"embarrassing\", \"humiliating\"},\n",
        "                    \"guilt\":{\"blame\", \"contrition\", \"remorse\"},\n",
        "                    \"disgust\":{\"abhor\", \"aversion\", \"dislike\", \"disrelish\", \"nausea\",\"sick\"},\n",
        "                    \"contempt\":{\"denigration\",\"depreciate\",\"derision\",\"disdain\",\"scorn\"},\n",
        "                    \"hostile\":{},\n",
        "                    \"anger\":{\"anger\",\"angry\",\"furious\",\"fury\",\"incense\",\"infuriating\",\n",
        "                                \"mad\",\"rage\",\"resent\",\"temper\",\"wrath\"},\n",
        "                    \"recognition\":{\"respect\",\"acknowledgement\"}\n",
        "            }\n",
        "dict_embedding = get_embedding(\"glove.en.100.txt\")\n",
        "kdtree_embedding = KDTreeEmbedding(dict_embedding, \"kdt_en.p\")\n",
        "\n",
        "#obtem as stopwords\n",
        "stop_words = set()\n",
        "with open(\"datasets/stopwords.txt\") as stop_file:\n",
        "    stop_words = set(stop_word[:-1] for stop_word in stop_file)\n",
        "\n",
        "\n",
        "#palavras chaves a serem consideradas\n",
        "set_vocabulary = set()\n",
        "for key_word, arr_related_words in emotion_words.items():\n",
        "    set_vocabulary.add(key_word)\n",
        "    set_vocabulary = set_vocabulary | set(arr_related_words)\n",
        "\n",
        "#kdtree - para gerar o conjunto com palavras chaves e suas similares\n",
        "vocabulary_expanded = []\n",
        "for word in set_vocabulary:\n",
        "    _, words = kdtree_embedding.get_most_similar_embedding(word,60)\n",
        "    vocabulary_expanded.extend(words)\n",
        "vocabulary_expanded = set(vocabulary_expanded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6nZahvORKIJ"
      },
      "source": [
        "\n",
        "\n",
        "**Representações usadas**: Iremos avaliar a filtragem de stopwords e usando um vocabulário restrito da representação bag of words e também da representação usando a média de embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Y_bjVPx2RKIJ"
      },
      "outputs": [],
      "source": [
        "from embeddings.textual_representation import BagOfWords, AggregateEmbeddings,InstanceWisePreprocess\n",
        "\n",
        "#gera as representações\n",
        "aggregate = AggregateEmbeddings(dict_embedding, \"avg\")\n",
        "embedding = InstanceWisePreprocess(\"embbeding\",aggregate)\n",
        "\n",
        "aggregate_stop = AggregateEmbeddings(dict_embedding, \"avg\",words_to_filter=stop_words)\n",
        "emb_nostop = InstanceWisePreprocess(\"emb_nostop\",aggregate_stop)\n",
        "\n",
        "\n",
        "aggregate_keywords_exp = AggregateEmbeddings(dict_embedding, \"avg\",words_to_consider=vocabulary_expanded)\n",
        "emb_keywords_exp = InstanceWisePreprocess(\"emb_keywords_exp\",aggregate_keywords_exp)\n",
        "\n",
        "bow_keywords = BagOfWords(\"bow_keywords_exp\", words_to_consider=vocabulary_expanded)\n",
        "bow = BagOfWords(\"bow\", stop_words=stop_words)\n",
        "\n",
        "arr_representations = [embedding,emb_nostop, emb_keywords_exp, bow,bow_keywords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rQIBSU90RKIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "fd916382-d73a-4fbf-a1e0-fb57111b07fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     class\n",
              "id                                                                 \n",
              "204215  Do NOT WASTE Your Time: This book, to put it n...  negative\n",
              "208138  Peels the paint off the walls: I first heard t...  positive\n",
              "157010  History With Modern Appeal: This is a must rea...  positive\n",
              "274316  Worse Music cd ever: I tried putting this in a...  negative\n",
              "57708   Deliberately Obtuse Nonsense: I don't know wha...  negative\n",
              "...                                                   ...       ...\n",
              "29215   Better than the movie?: YES! This book gets be...  positive\n",
              "256457  The Best RE yet: This is the best in the RE se...  positive\n",
              "210215  What are they waiting for?: This has got to be...  positive\n",
              "200693  Hollywood - promoting the Antichrist again?: C...  negative\n",
              "169551  Best American TV Series Ever: With its combina...  positive\n",
              "\n",
              "[3000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8077b974-d1ce-4eff-b7f8-198df020f1d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204215</th>\n",
              "      <td>Do NOT WASTE Your Time: This book, to put it n...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208138</th>\n",
              "      <td>Peels the paint off the walls: I first heard t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157010</th>\n",
              "      <td>History With Modern Appeal: This is a must rea...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274316</th>\n",
              "      <td>Worse Music cd ever: I tried putting this in a...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57708</th>\n",
              "      <td>Deliberately Obtuse Nonsense: I don't know wha...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29215</th>\n",
              "      <td>Better than the movie?: YES! This book gets be...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256457</th>\n",
              "      <td>The Best RE yet: This is the best in the RE se...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210215</th>\n",
              "      <td>What are they waiting for?: This has got to be...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200693</th>\n",
              "      <td>Hollywood - promoting the Antichrist again?: C...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169551</th>\n",
              "      <td>Best American TV Series Ever: With its combina...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8077b974-d1ce-4eff-b7f8-198df020f1d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8077b974-d1ce-4eff-b7f8-198df020f1d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8077b974-d1ce-4eff-b7f8-198df020f1d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-73094fa7-8467-4ce3-9422-5ff3e72766d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73094fa7-8467-4ce3-9422-5ff3e72766d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-73094fa7-8467-4ce3-9422-5ff3e72766d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.read_csv(\"datasets/amazon_reviews_mini.txt\",index_col=\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLXID-9RRKIK"
      },
      "source": [
        "Abaixo, é executado um método de aprendizado  para cada representação. Esse processo pode demorar um pouco pois é feito a procura do melhor parametro do algoritmo. Algumas otimizações que talvez, você precise fazer é no arquivo `embedding/avaliacao_embedding.py` alterar o parametro `n_jobs` no método `obtem_metodo` da classe `OtimizacaoObjetivoRandomForest`. Esse parametro é responsável por utiizar mais threads ao executar o Random Forests.  O valor pode ser levemente inferior a quantidades de núcleos que seu computador tem, caso ele tenha mais de 2, caso contrário, o ideal é colocarmos `n_jobs=1`. Caso queira visualizar resultados mais rapidamente, diminua o valor da variável `num_trials` e `num_folds` abaixo. Atenção que `num_folds` deve ser um valor maior que um."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDGpdtextRhf",
        "outputId": "92177edb-0ef2-432d-d3f2-91930f51c98f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Using cached optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.0-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.0 colorlog-6.8.0 optuna-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "vKiz8U99RKIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4555131-04b8-45a2-8404-c9ad5f63136e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Representação: embbeding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-06 10:38:43,998] A new study created in RDB with name: random_forest_embbeding_fold_0\n",
            "[I 2023-12-06 10:39:12,850] Trial 0 finished with value: 0.7026844411452852 and parameters: {'min_samples_split': 9, 'max_features': 95, 'num_arvores': 30}. Best is trial 0 with value: 0.7026844411452852.\n",
            "[I 2023-12-06 10:39:32,862] Trial 1 finished with value: 0.7076808594215102 and parameters: {'min_samples_split': 7, 'max_features': 75, 'num_arvores': 30}. Best is trial 1 with value: 0.7076808594215102.\n",
            "[I 2023-12-06 10:39:56,141] Trial 2 finished with value: 0.7257292199352072 and parameters: {'min_samples_split': 5, 'max_features': 80, 'num_arvores': 35}. Best is trial 2 with value: 0.7257292199352072.\n",
            "[I 2023-12-06 10:40:18,150] Trial 3 finished with value: 0.7100922628235254 and parameters: {'min_samples_split': 11, 'max_features': 80, 'num_arvores': 45}. Best is trial 2 with value: 0.7257292199352072.\n",
            "[I 2023-12-06 10:40:41,140] Trial 4 finished with value: 0.7093917088711424 and parameters: {'min_samples_split': 5, 'max_features': 100, 'num_arvores': 30}. Best is trial 2 with value: 0.7257292199352072.\n",
            "[I 2023-12-06 10:41:01,646] Trial 5 finished with value: 0.6963224688291163 and parameters: {'min_samples_split': 15, 'max_features': 80, 'num_arvores': 40}. Best is trial 2 with value: 0.7257292199352072.\n",
            "[I 2023-12-06 10:41:26,657] Trial 6 finished with value: 0.7187088565569706 and parameters: {'min_samples_split': 3, 'max_features': 75, 'num_arvores': 50}. Best is trial 2 with value: 0.7257292199352072.\n",
            "[I 2023-12-06 10:41:47,856] Trial 7 finished with value: 0.683282053795201 and parameters: {'min_samples_split': 21, 'max_features': 80, 'num_arvores': 45}. Best is trial 2 with value: 0.7257292199352072.\n",
            "[I 2023-12-06 10:42:07,027] Trial 8 finished with value: 0.6797143711243168 and parameters: {'min_samples_split': 19, 'max_features': 100, 'num_arvores': 30}. Best is trial 2 with value: 0.7257292199352072.\n",
            "[I 2023-12-06 10:42:33,571] Trial 9 finished with value: 0.7340698717945805 and parameters: {'min_samples_split': 1, 'max_features': 75, 'num_arvores': 50}. Best is trial 9 with value: 0.7340698717945805.\n",
            "[I 2023-12-06 10:42:58,825] Trial 10 finished with value: 0.7294750600144275 and parameters: {'min_samples_split': 1, 'max_features': 70, 'num_arvores': 50}. Best is trial 9 with value: 0.7340698717945805.\n",
            "[I 2023-12-06 10:43:25,910] Trial 11 finished with value: 0.7294750600144275 and parameters: {'min_samples_split': 1, 'max_features': 70, 'num_arvores': 50}. Best is trial 9 with value: 0.7340698717945805.\n",
            "[I 2023-12-06 10:43:50,814] Trial 12 finished with value: 0.7277901152580846 and parameters: {'min_samples_split': 1, 'max_features': 70, 'num_arvores': 45}. Best is trial 9 with value: 0.7340698717945805.\n",
            "[I 2023-12-06 10:44:14,240] Trial 13 finished with value: 0.7000626804630237 and parameters: {'min_samples_split': 15, 'max_features': 90, 'num_arvores': 50}. Best is trial 9 with value: 0.7340698717945805.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from embeddings.avaliacao_embedding import calcula_experimento_representacao, OtimizacaoObjetivoRandomForest\n",
        "\n",
        "# Método de aprendizado de máquina a ser usado\n",
        "dict_metodo = {\"random_forest\":{\"classe_otimizacao\":OtimizacaoObjetivoRandomForest,\n",
        "                                \"sampler\":optuna.samplers.TPESampler(seed=1, n_startup_trials=10)},\n",
        "              }\n",
        "df_amazon_reviews = pd.read_csv(\"datasets/amazon_reviews_mini.txt\",index_col=\"id\")\n",
        "\n",
        "#executa experimento com a representacao determinada e o método\n",
        "for metodo, param_metodo in dict_metodo.items():\n",
        "    for representation in arr_representations:\n",
        "        print(f\"===== Representação: {representation.nome}\")\n",
        "        col_classe = \"class\"\n",
        "        num_folds = 5\n",
        "        num_folds_validacao = 3\n",
        "        num_trials = 100\n",
        "\n",
        "\n",
        "        nom_experimento = f\"{metodo}_\"+representation.nome\n",
        "        experimento = calcula_experimento_representacao(nom_experimento,representation,df_amazon_reviews,\n",
        "                                            col_classe,num_folds,num_folds_validacao,num_trials,\n",
        "                                            ClasseObjetivoOtimizacao=param_metodo['classe_otimizacao'],\n",
        "                                                sampler=param_metodo['sampler'])\n",
        "        print(f\"Representação: {representation.nome} concluida\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9JhXU1XRKIK"
      },
      "source": [
        "Como a experimentação é uma tarefa custosa, todos os resultados são salvos na pasta \"resultados\" - inclusive os valores dos parametros na classe optuna (a prática de avaliação apresenta mais detalhes da biblioteca Optuna). A macro f1 é uma métrica relacionada a taxa de acerto (se necessário, [veja a explicação neste video - tópico 2 e 3)](https://www.youtube.com/watch?v=u7o7CSeXaNs&list=PLwIaU1DGYV6tUx10fCTw5aPnqypbbK_GJ&index=13). Analise os resultados abaixo: qual representação foi melhor? A restrição de vocabulário ou eliminação de stopwords auxiliou?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxV4J7n3RKIK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from base_am.avaliacao import Experimento\n",
        "\n",
        "arr_resultado = []\n",
        "results_folder = \"resultados\"\n",
        "if not os.path.exists(results_folder):\n",
        "    os.makedirs(results_folder)\n",
        "for resultado_csv in os.listdir(\"resultados\"):\n",
        "    if resultado_csv.endswith(\"csv\"):\n",
        "        nom_experimento = resultado_csv.split(\".\")[0]\n",
        "\n",
        "        #carrega resultados previamente realizados\n",
        "        experimento = Experimento(nom_experimento,[])\n",
        "        experimento.carrega_resultados_existentes()\n",
        "\n",
        "        #adiciona experimento\n",
        "        num_folds = len(experimento.resultados)\n",
        "        dict_resultados = {\"nom_experimento\":nom_experimento,\n",
        "                            \"macro-f1\":sum([r.macro_f1 for r in experimento.resultados])/num_folds}\n",
        "        #resultados por classe\n",
        "        for classe in experimento.resultados[0].mat_confusao.keys():\n",
        "\n",
        "            dict_resultados[f\"f1-{classe}\"] = sum([r.f1_por_classe[classe] for r in experimento.resultados])/num_folds\n",
        "            dict_resultados[f\"precision-{classe}\"] = sum([r.precisao[classe] for r in experimento.resultados])/num_folds\n",
        "            dict_resultados[f\"recall-{classe}\"] = sum([r.revocacao[classe] for r in experimento.resultados])/num_folds\n",
        "\n",
        "        arr_resultado.append(dict_resultados)\n",
        "\n",
        "pd.DataFrame.from_dict(arr_resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNs4NZCLRKIK"
      },
      "source": [
        "## Bibliografia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSyhd1BeRKIL"
      },
      "source": [
        "Bolukbasi, T., Chang, K. W., Zou, J., Saligrama, V., & Kalai, A. (2016). **[Man is to computer programmer as woman is to homemaker? Debiasing word embeddings](https://arxiv.org/abs/1607.06520)**.\n",
        "\n",
        "Hartmann, N., Fonseca, E., Shulby, C., Treviso, M., Rodrigues, J., & Aluisio, S. (2017). [**Portuguese word embeddings: Evaluating on word analogies and natural language tasks.**](https://arxiv.org/abs/1708.06025)\n",
        "\n",
        "\n",
        "Pennington, J., Socher, R., & Manning, C. D. (2014, October).**[GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)**. In EMNLP 2015\n",
        "\n",
        "\n",
        "Scherer, Klaus R. **[What are emotions? And how can they be measured?](https://journals.sagepub.com/doi/pdf/10.1177/0539018405058216)**. Social science information, v. 44, n. 4, p. 695-729, 2005.\n",
        "\n",
        "Shen, D., Wang, G., Wang, W., Min, M. R., Su, Q., Zhang, Y., Carin, L. (2018). [Baseline needs more love: On simple word-embedding-based models and associated pooling mechanisms](https://arxiv.org/pdf/1805.09843.pdf).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xGtwEoNRKIL"
      },
      "source": [
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Licença Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />Este obra está licenciado com uma Licença <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Atribuição-CompartilhaIgual 4.0 Internacional</a>."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}